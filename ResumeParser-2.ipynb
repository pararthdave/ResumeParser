{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResumeParser.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNTymhbQVSVt",
        "outputId": "51857be9-d490-497a-f0cc-fab6317af345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 19.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 4.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pypdf2\n",
            "  Building wheel for pypdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypdf2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61102 sha256=1d3b08f4901d0ecf0b686588496ff5e5f075a53fbcfde46b4fbcdd21ba67903c\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1a/24/648467ade3a77ed20f35cfd2badd32134e96dd25ca811e64b3\n",
            "Successfully built pypdf2\n",
            "Installing collected packages: pypdf2\n",
            "Successfully installed pypdf2-1.26.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pypdf2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install build-essential libpoppler-cpp-dev pkg-config python3-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTK-75WuNLim",
        "outputId": "105539e4-3af2-4692-da01-672cdb3ca777"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu2).\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "python3-dev set to manually installed.\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  libpoppler-cpp0v5\n",
            "The following NEW packages will be installed:\n",
            "  libpoppler-cpp-dev libpoppler-cpp0v5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 36.7 kB of archives.\n",
            "After this operation, 188 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpoppler-cpp0v5 amd64 0.62.0-2ubuntu2.12 [28.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpoppler-cpp-dev amd64 0.62.0-2ubuntu2.12 [8,676 B]\n",
            "Fetched 36.7 kB in 1s (49.3 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpoppler-cpp0v5:amd64.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../libpoppler-cpp0v5_0.62.0-2ubuntu2.12_amd64.deb ...\n",
            "Unpacking libpoppler-cpp0v5:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Selecting previously unselected package libpoppler-cpp-dev:amd64.\n",
            "Preparing to unpack .../libpoppler-cpp-dev_0.62.0-2ubuntu2.12_amd64.deb ...\n",
            "Unpacking libpoppler-cpp-dev:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Setting up libpoppler-cpp0v5:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Setting up libpoppler-cpp-dev:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdftotext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzuEAcR-MvWe",
        "outputId": "36b70efb-335b-4385-8a0b-06ba5b79c75b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdftotext\n",
            "  Downloading pdftotext-2.2.2.tar.gz (113 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 30 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 40 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 51 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 71 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 81 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 92 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 113 kB 8.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pdftotext\n",
            "  Building wheel for pdftotext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdftotext: filename=pdftotext-2.2.2-cp37-cp37m-linux_x86_64.whl size=54896 sha256=6c53c678f2dce6275381706475a2f9e7c5fd9c5ac9e448c5822cb28efa9325c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/19/8e/e8648026db8b7ef3324ad9afa1f7c9109a7e7509846f693ed9\n",
            "Successfully built pdftotext\n",
            "Installing collected packages: pdftotext\n",
            "Successfully installed pdftotext-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -rv /content/drive/MyDrive/ResumeParser/Dataset/dataset.zip ."
      ],
      "metadata": {
        "id": "86EDFQZOX5nQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6fb96f-6af2-4e14-b238-35c1be7c886a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/ResumeParser/Dataset/dataset.zip' -> './dataset.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xspT_wIsaTaf",
        "outputId": "8940a1f2-d8a7-4319-f721-4034a59c3bf6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset.zip\n",
            "   creating: dataset/\n",
            "  inflating: dataset/Harika Sonnathi Resume 2022 2.pdf  \n",
            "  inflating: dataset/KetanPawarResume.pdf  \n",
            "  inflating: dataset/Mandar bhoir Resume (1)_compressed.pdf  \n",
            "  inflating: dataset/pararthdave_Resume.pdf  \n",
            "  inflating: dataset/Priyanka_RaikwarRESUME.pdf  \n",
            "  inflating: dataset/priyanka_resume(8).pdf  \n",
            "  inflating: dataset/ravisatvik.192_Resume.pdf  \n",
            "  inflating: dataset/YOGAPRIYA H_RESUME.pdf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import PyPDF2\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "import pdftotext\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "CHBlIWIGVb1O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTGsb134uBhr",
        "outputId": "fcc7dd1b-b6bb-40ca-d4d0-95a1066c1228"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/dataset' #file path for corpus\n",
        "files = [os.path.join (path, f) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
        "pdfs = []\n",
        "for i in files:\n",
        "    pdfs.append(i)\n",
        "\n",
        "merger = PyPDF2.PdfFileMerger(strict=False)\n",
        "\n",
        "for pdf in pdfs:\n",
        "    merger.append(pdf)\n",
        "\n",
        "merger.write(\"final.pdf\")\n",
        "\n",
        "# reader = PyPDF2.PdfFileReader('final.pdf', strict=False)\n",
        "# page = reader.getNumPages()\n",
        "# count = 0\n",
        "# text = []\n",
        "# while count < page:    \n",
        "#     pageObj = reader.getPage(count)\n",
        "#     count +=1\n",
        "#     t = pageObj.extractText().strip()\n",
        "#     text.append(t)\n",
        "# print(text[3])"
      ],
      "metadata": {
        "id": "pwqdrRBRVoLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de763c35-772f-4949-8942-600148c8a720"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PdfReadWarning: Multiple definitions in dictionary at byte 0x2379 for key /h.6dzabhgz4wnn [generic.py:588]\n",
            "PdfReadWarning: Multiple definitions in dictionary at byte 0x23d7 for key /h.xzo9n6yunfn [generic.py:588]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"final.pdf\", \"rb\") as f:\n",
        "    pdf = pdftotext.PDF(f)"
      ],
      "metadata": {
        "id": "Xjc-6uuYayP9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalpg=[]\n",
        "for page in pdf:\n",
        "    pg=page.strip()\n",
        "    finalpg.append(pg)\n",
        "print(finalpg[2])"
      ],
      "metadata": {
        "id": "JrvWpc7U5XUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a166f167-8147-4d50-d407-a0a3cbfb1541"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/4/2021                                                                        202018016_Resume\n",
            " PROJECTS\n",
            " Project Fidget                           A utility web app was developed under the guidance of IRLAB-DAIICT         May 2021- Ongoing\n",
            "                                          based on the projects of the second semester. This was an ambitious\n",
            " Guide:                                                                                                                  Team Size - 07\n",
            "                                          project that had three-module namely Sentiment Analysis of YouTube\n",
            " Dr. Prasenjit Majumder\n",
            "                                          Videos, Stock Market Prediction, and Power Utilization Prediction\n",
            "                                          Front-End: Django, JavaScript, CSS, HTML5, Bootstrap\n",
            "                                          Back-End: Python, Linux Shell\n",
            " UI for Legal Document                    Project in collaboration with IIT Kharagpur, the algorithm was provided to           2021-22\n",
            " Summarization                            us and we built an interactive UI that also enabled Human-Computer\n",
            "                                                                                                                        Team Size: - 02\n",
            " (DELSumm)                                Interaction\n",
            " Guide:\n",
            " Dr. Prasenjit Majumder\n",
            " Stock Market Prediction Stock prices of nifty fifty stock were aimed to predict on a minute basis                               2021\n",
            "                                          after having around an hour's worth of historical data. Also, the system\n",
            " Guide:                                                                                                                 Team Size: - 07\n",
            "                                          was self-sustaining and was under continuous learning. It was able to\n",
            " Dr. Prasenjit Majumdar\n",
            "                                          predict the increase/decrease of certain parameters. Concepts like web\n",
            "                                          scrapping, ARIMA, LSTM were learned.\n",
            "                                          Front-End: Streamlit\n",
            "                                          Back-End: Python, Linux Shell\n",
            " Plasma Classification                    Plasma movement, size, and existence were aimed to calculated in this                  2021\n",
            "                                          project. Confidential data available with NRC, Ahmedabad was used to\n",
            " Guide: Nabin Sahu                                                                                                      Team Size: - 05\n",
            "                                          accomplish this feat. Various numerical methods, image processing\n",
            "                                          techniques were learned. Streamlit was used as GUI.\n",
            "                                          Front-End: Streamlit\n",
            "                                          Back-End: Python, Linux Shell\n",
            " Sentiment Analysis                       Sentiment analysis of youtube videos as well as sentences that are                     2021\n",
            "                                          inputted into the system. The aim was to predict emotion out of a\n",
            " Guide:                                                                                                                 Team Size: - 04\n",
            "                                          spectrum of 6 and positive/negative polarity. Made using various python\n",
            " Dr. Prasenjit Majumdar\n",
            "                                          libraries and concepts like clustering and classification were learned.\n",
            "                                          Streamlit was used as GUI.\n",
            "                                          Front-End: Streamlit\n",
            "                                          Back-End: Python, Linux Shell\n",
            " Customer Segmentation A clustering problem of dividing the customers into groups based on the                                   2021\n",
            "                                          patterns noticed in their buying style. Agglomerative and K-Means\n",
            " Guide: Dr. Ahlad Kumar                                                                                                 Team Size: - 04\n",
            "                                          Clustering was used along with an ensemble of both in order to achieve\n",
            "                                          the highest accuracy possible. Various clustering techniques and python\n",
            "                                          libraries were learned and used in the same.\n",
            "                                          Back-End: Python\n",
            " Harry Potter Fandom                      HP Fandom website made using HTML5, CSS, and Bootstrap. At the same               2020-2021\n",
            " Website                                  time, Django and Sqlite3 are used for connection and backend. The\n",
            "                                                                                                                        Team Size: - 03\n",
            "                                          website can take data from the user in the form of forms and store it in a\n",
            " Guide:\n",
            "                                          database table. The website is responsive and contained various pages to\n",
            " Mrs. Sujata Prakash\n",
            "                                          interact as per the interests and requirements. The website is being\n",
            "                                          hosted on Heroku, but the backend failed in the process of the same.\n",
            "                                          Front-End: Django, HTML5, Bootstrap, CSS\n",
            "                                          Back-End: Python\n",
            "                                          URL: - http://hpfandom.herokuapp.com\n",
            "https://daiict-placement-cell.github.io/ResumeMaker/resume_daiict_regular.html                                                        2/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# initialize matcher with a vocab\n",
        "matcher = Matcher(nlp.vocab, validate=True)\n",
        "\n",
        "def extract_name(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "    \n",
        "    # First name and Last name are always Proper Nouns\n",
        "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "    \n",
        "    matcher.add('NAME', None, [pattern])\n",
        "    \n",
        "    matches = matcher(nlp_text)\n",
        "    \n",
        "    for match_id, start, end in matches:\n",
        "        span = nlp_text[start:end]\n",
        "        return span.text"
      ],
      "metadata": {
        "id": "OlHrgGDatJpe"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_name(finalpg[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "MYyiI8Ogx11b",
        "outputId": "9a75059c-ac1c-4b27-d0fc-4b54483ce823"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MatchPatternError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMatchPatternError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-14baa0e0be3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinalpg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-72-dfe695c208a4>\u001b[0m in \u001b[0;36mextract_name\u001b[0;34m(resume_text)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'POS'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'PROPN'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NAME'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmatcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.matcher.Matcher.add\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mMatchPatternError\u001b[0m: Invalid token patterns for matcher rule 'NAME'\n\nPattern 0:\n- [{'POS': 'PROPN'}] is not of type 'object' [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(finalpg[0])\n",
        "\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "            token.shape_, token.is_alpha, token.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPqm5lGtue7N",
        "outputId": "d7a01b87-3fbe-4766-82d4-21172c7c9009"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOGAPRIYA YOGAPRIYA PROPN NNP compound XXXX True False\n",
            "HARIBASKAR HARIBASKAR PROPN NNP ROOT XXXX True False\n",
            "\n",
            "        \n",
            "        SPACE _SP  \n",
            "     False False\n",
            "+91 +91 NUM CD ROOT +dd False False\n",
            "7010842961 7010842961 NUM CD nummod dddd False False\n",
            "                                    SPACE _SP       False False\n",
            "yogapriyaharibaskar1806@gmai yogapriyaharibaskar1806@gmai PROPN NNP ROOT xxxxdddd@xxxx False False\n",
            "            SPACE _SP       False False\n",
            "Namakkal Namakkal PROPN NNP conj Xxxxx True False\n",
            ", , PUNCT , punct , False False\n",
            "India India PROPN NNP intj Xxxxx True False\n",
            "                            SPACE _SP       False False\n",
            "www.linkedin.com/in/yogapriya- www.linkedin.com/in/yogapriya- PROPN NNP conj xxx.xxxx.xxx/xx/xxxx- False False\n",
            "\n",
            "                                        \n",
            "                                        SPACE _SP  \n",
            "     False False\n",
            "l.com l.com PROPN NNP ROOT x.xxx False False\n",
            "                                                                                                                    SPACE _SP       False False\n",
            "haribaskar-29155014b haribaskar-29155014b PROPN NNP ROOT xxxx-ddddx False False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "OBJECTIVE OBJECTIVE PROPN NNP ROOT XXXX True False\n",
            "                                                                                                                                                          SPACE _SP       False False\n",
            "TECHNICAL TECHNICAL PROPN NNP compound XXXX True False\n",
            "SKILLS skill VERB VBZ ROOT XXXX True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "To to PART TO aux Xx True True\n",
            "be be AUX VB ROOT xx True True\n",
            "a a DET DT det x True True\n",
            "part part NOUN NN attr xxxx True True\n",
            "of of ADP IN prep xx True True\n",
            "a a DET DT det x True True\n",
            "competitive competitive ADJ JJ amod xxxx True False\n",
            "organization organization NOUN NN pobj xxxx True False\n",
            "that that DET WDT nsubj xxxx True True\n",
            "provides provide VERB VBZ relcl xxxx True False\n",
            "scope scope NOUN NN dobj xxxx True False\n",
            "to to PART TO aux xx True True\n",
            "apply apply VERB VB xcomp xxxx True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "my -PRON- DET PRP$ poss xx True True\n",
            "skills skill NOUN NNS dobj xxxx True False\n",
            ", , PUNCT , punct , False False\n",
            "also also ADV RB advmod xxxx True True\n",
            "to to PART TO aux xx True True\n",
            "improve improve VERB VB advcl xxxx True False\n",
            "my -PRON- DET PRP$ poss xx True True\n",
            "knowledge knowledge NOUN NN dobj xxxx True False\n",
            "in in ADP IN prep xx True True\n",
            "the the DET DT det xxx True True\n",
            "software software NOUN NN compound xxxx True False\n",
            "industry industry NOUN NN pobj xxxx True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "and and CCONJ CC cc xxx True True\n",
            "current current ADJ JJ amod xxxx True False\n",
            "technologies technology NOUN NNS conj xxxx True False\n",
            ". . PUNCT . punct . False False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "EXPERIENCE experience ADV RB ROOT XXXX True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "SIAM SIAM PROPN NNP compound XXXX True False\n",
            "COMPUTING COMPUTING PROPN NNP ROOT XXXX True False\n",
            ", , PUNCT , punct , False False\n",
            "Chennai Chennai PROPN NNP appos Xxxxx True False\n",
            "– – PUNCT : punct – False False\n",
            "Machine Machine PROPN NNP compound Xxxxx True False\n",
            "Learning Learning PROPN NNP compound Xxxxx True False\n",
            "Intern Intern PROPN NNP compound Xxxxx True False\n",
            "                                                                          SPACE _SP       False False\n",
            "AREAS AREAS PROPN NNP ROOT XXXX True False\n",
            "OF of ADP IN prep XX True True\n",
            "INTEREST INTEREST PROPN NNP pobj XXXX True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "SUMMER SUMMER NOUN NNS compound XXXX True False\n",
            "INTERN intern NOUN NN compound XXXX True False\n",
            "MAY MAY PROPN NNP ROOT XXX True True\n",
            ", , PUNCT , punct , False False\n",
            "2020 2020 NUM CD npadvmod dddd False False\n",
            "\n",
            "  \n",
            "  SPACE _SP  \n",
            "  False False\n",
            "• • X XX nsubj • False False\n",
            "      SPACE _SP     False False\n",
            "Developed develop VERB VBD ROOT Xxxxx True False\n",
            "a a DET DT det x True True\n",
            "web web NOUN NN compound xxx True False\n",
            "application application NOUN NN dobj xxxx True False\n",
            "to to PART TO aux xx True True\n",
            "automatically automatically ADV RB advmod xxxx True False\n",
            "evaluate evaluate VERB VB relcl xxxx True False\n",
            "answer answer NOUN NN compound xxxx True False\n",
            "sheets sheet NOUN NNS dobj xxxx True False\n",
            "\n",
            "      \n",
            "      SPACE _SP  \n",
            "     False False\n",
            "using use VERB VBG advcl xxxx True True\n",
            "Natural Natural PROPN NNP compound Xxxxx True False\n",
            "Language Language PROPN NNP compound Xxxxx True False\n",
            "Processing Processing PROPN NNP dobj Xxxxx True False\n",
            ". . PUNCT . punct . False False\n",
            "\n",
            "  \n",
            "  SPACE _SP  \n",
            "  False False\n",
            "• • X ADD ROOT • False False\n",
            "      SPACE _SP     False False\n",
            "Explored Explored PROPN NNP amod Xxxxx True False\n",
            "DJANGO DJANGO PROPN NNP compound XXXX True False\n",
            "framework framework NOUN NN ROOT xxxx True False\n",
            "and and CCONJ CC cc xxx True True\n",
            "Wordpress Wordpress PROPN NNP compound Xxxxx True False\n",
            "Technology Technology PROPN NNP conj Xxxxx True False\n",
            "\n",
            "                                                                                       \n",
            "                                                                                       SPACE _SP  \n",
            "     False False\n",
            "EX EX PROPN NNP compound XX True False\n",
            "- - PUNCT HYPH punct - False False\n",
            "CURRICULAR CURRICULAR PROPN NNP compound XXXX True False\n",
            "ACTIVITIES activity NOUN NNS ROOT XXXX True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "EDUCATION EDUCATION PROPN NNP ROOT XXXX True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "M.Sc M.Sc PROPN NNP compound X.Xx False False\n",
            "Data Data PROPN NNP compound Xxxx True False\n",
            "Science Science PROPN NNP ROOT Xxxxx True False\n",
            "                                                                                                      SPACE _SP       False False\n",
            "2017 2017 NUM CD punct dddd False False\n",
            "- - PUNCT : punct - False False\n",
            "Present present NOUN NN ROOT Xxxxx True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "Coimbatore Coimbatore PROPN NNP nmod Xxxxx True False\n",
            "Instituteof Instituteof PROPN NNP compound Xxxxx True False\n",
            "Technology Technology PROPN NNP cc Xxxxx True False\n",
            "| | PROPN NNP compound | False False\n",
            "CGPA CGPA PROPN NNP ROOT XXXX True False\n",
            ": : PUNCT : punct : False False\n",
            "7.60 7.60 NUM CD appos d.dd False False\n",
            "up up ADP IN prep xx True True\n",
            "to to ADP IN prep xx True True\n",
            "8th 8th ADJ JJ amod dxx False False\n",
            "semester semester NOUN NN pobj xxxx True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "Class Class PROPN NNP compound Xxxxx True False\n",
            "XII XII PROPN NNP appos XXX True False\n",
            "( ( PUNCT -LRB- punct ( False False\n",
            "HSC HSC PROPN NNP appos XXX True False\n",
            ") ) PUNCT -RRB- punct ) False False\n",
            "                                                                                                      SPACE _SP       False False\n",
            "2016 2016 NUM CD npadvmod dddd False False\n",
            "- - SYM SYM punct - False False\n",
            "2017 2017 NUM CD prep dddd False False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "Adharsh Adharsh PROPN NNP compound Xxxxx True False\n",
            "Vidhyalaya Vidhyalaya PROPN NNP compound Xxxxx True False\n",
            "Higher Higher PROPN NNP compound Xxxxx True False\n",
            "Secondary Secondary PROPN NNP compound Xxxxx True False\n",
            "School School PROPN NNP ROOT Xxxxx True False\n",
            ", , PUNCT , punct , False False\n",
            "Erode Erode PROPN NNP appos Xxxxx True False\n",
            "| | PROPN NNP nmod | False False\n",
            "90.00 90.00 NUM CD nummod dd.dd False False\n",
            "% % NOUN NN appos % False False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "Class class NOUN NN compound Xxxxx True False\n",
            "X X PROPN NNP dep X True False\n",
            "( ( PUNCT -LRB- punct ( False False\n",
            "SSLC SSLC PROPN NNP nmod XXXX True False\n",
            ") ) PUNCT -RRB- punct ) False False\n",
            "                                                                                                        SPACE _SP       False False\n",
            "2014 2014 NUM CD nummod dddd False False\n",
            "- - SYM SYM punct - False False\n",
            "2015 2015 NUM CD prep dddd False False\n",
            "              SPACE _SP       False False\n",
            "GITHUB GITHUB PROPN NNP compound XXXX True False\n",
            "REPOSITORY REPOSITORY PROPN NNP ROOT XXXX True False\n",
            ": : PUNCT : punct : False False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "R.N.Oxford R.N.Oxford PROPN NNP ROOT X.X.Xxxxx False False\n",
            ", , PUNCT , punct , False False\n",
            "Namakkal Namakkal PROPN NNP compound Xxxxx True False\n",
            "| | PROPN NNP appos | False False\n",
            "97.00 97.00 NUM CD nummod dd.dd False False\n",
            "% % NOUN NN ROOT % False False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "PROJECTS PROJECTS PROPN NNP appos XXXX True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "EDUTECH edutech NOUN NN ROOT XXXX True False\n",
            "                                                                                      SPACE _SP       False False\n",
            "[ [ PUNCT -LRB- punct [ False False\n",
            "HTML html NOUN NN ROOT XXXX True False\n",
            ", , PUNCT , punct , False False\n",
            "CSS CSS PROPN NNP conj XXX True False\n",
            ", , PUNCT , punct , False False\n",
            "Python Python PROPN NNP conj Xxxxx True False\n",
            ", , PUNCT , punct , False False\n",
            "Django Django PROPN NNP appos Xxxxx True False\n",
            "] ] PUNCT -RRB- punct ] False False\n",
            "                  SPACE _SP       False False\n",
            "CO CO PROPN NNP compound XX True False\n",
            "- - PUNCT HYPH punct - False False\n",
            "CURRICULAR CURRICULAR PROPN NNP compound XXXX True False\n",
            "ACTIVITIES ACTIVITIES PROPN NNPS ROOT XXXX True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "Description description NOUN NN ROOT Xxxxx True False\n",
            ": : PUNCT : punct : False False\n",
            "A a DET DT det X True True\n",
            "web web NOUN NN compound xxx True False\n",
            "application application NOUN NN ROOT xxxx True False\n",
            "to to PART TO aux xx True True\n",
            "automatically automatically ADV RB advmod xxxx True False\n",
            "evaluate evaluate VERB VB relcl xxxx True False\n",
            "answer answer NOUN NN compound xxxx True False\n",
            "sheets sheet NOUN NNS dobj xxxx True False\n",
            "                                      SPACE _SP       False False\n",
            "• • PROPN NNP nsubj • False False\n",
            "Attended attend VERB VBD ROOT Xxxxx True False\n",
            "workshop workshop NOUN NN dobj xxxx True False\n",
            "on on ADP IN prep xx True True\n",
            "machine machine NOUN NN nmod xxxx True False\n",
            "\n",
            "                                                                                            \n",
            "                                                                                            SPACE _SP  \n",
            "     False False\n",
            "learning learning NOUN NN pobj xxxx True False\n",
            "and and CCONJ CC cc xxx True True\n",
            "artificial artificial ADJ JJ amod xxxx True False\n",
            "intelligence intelligence NOUN NN conj xxxx True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "using use VERB VBG advcl xxxx True True\n",
            "Natural Natural PROPN NNP compound Xxxxx True False\n",
            "Language Language PROPN NNP compound Xxxxx True False\n",
            "Processing Processing PROPN NNP dobj Xxxxx True False\n",
            ". . PUNCT . punct . False False\n",
            "                                                                                                                  SPACE _SP       False False\n",
            "held hold VERB VBN ROOT xxxx True False\n",
            "by by ADP IN agent xx True True\n",
            "four four NUM CD nummod xxxx True True\n",
            "step step NOUN NN compound xxxx True False\n",
            "training training NOUN NN compound xxxx True False\n",
            "solutions solution NOUN NNS pobj xxxx True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "COVID COVID PROPN NNP compound XXXX True False\n",
            "DATA DATA PROPN NNP nmod XXXX True False\n",
            "ANALYSIS ANALYSIS PROPN NNP appos XXXX True False\n",
            "                                                              SPACE _SP       False False\n",
            "[ [ PUNCT -LRB- punct [ False False\n",
            "PowerBi PowerBi PROPN NNP ROOT XxxxxXx True False\n",
            ", , PUNCT , punct , False False\n",
            "Python Python PROPN NNP npadvmod Xxxxx True False\n",
            ", , PUNCT , punct , False False\n",
            "MySQL MySQL PROPN NNP appos XxXXX True False\n",
            "] ] PUNCT -RRB- punct ] False False\n",
            "\n",
            "                                                                                          \n",
            "                                                                                          SPACE _SP  \n",
            "     False False\n",
            "• • PUNCT . nmod • False False\n",
            "Active active ADJ JJ amod Xxxxx True False\n",
            "participant participant NOUN NN ROOT xxxx True False\n",
            "in in ADP IN prep xx True True\n",
            "Hackerrank Hackerrank PROPN NNP nmod Xxxxx True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "Description Description PROPN NNP pobj Xxxxx True False\n",
            ": : PUNCT : punct : False False\n",
            "This this DET DT nsubj Xxxx True True\n",
            "is be AUX VBZ ROOT xx True True\n",
            "a a DET DT det x True True\n",
            "dashboards dashboard NOUN NNS attr xxxx True False\n",
            "that that DET DT nsubj xxxx True True\n",
            "support support NOUN NN relcl xxxx True False\n",
            "’s ’s PUNCT '' punct ’x False True\n",
            "with with ADP IN prep xxxx True True\n",
            "COVID-19 covid-19 ADJ JJ compound XXXX-dd False False\n",
            "analytics analytic NOUN NNS pobj xxxx True False\n",
            "and and CCONJ CC cc xxx True True\n",
            "\n",
            "  \n",
            "  SPACE _SP  \n",
            "  False False\n",
            "better well ADJ JJR amod xxxx True False\n",
            "understanding understanding NOUN NN conj xxxx True False\n",
            "of of ADP IN prep xx True True\n",
            "the the DET DT det xxx True True\n",
            "impact impact NOUN NN pobj xxxx True False\n",
            "of of ADP IN prep xx True True\n",
            "COVID-19 covid-19 NOUN NN pobj XXXX-dd False False\n",
            ". . PUNCT . punct . False False\n",
            "Performance performance NOUN NN nsubj Xxxxx True False\n",
            "in in ADP IN prep xx True True\n",
            "the the DET DT det xxx True True\n",
            "technique technique NOUN NN pobj xxxx True False\n",
            "of of ADP IN prep xx True True\n",
            "                  SPACE _SP       False False\n",
            "• • PROPN NNP pobj • False False\n",
            "Presented present VERB VBD ROOT Xxxxx True False\n",
            "a a DET DT det x True True\n",
            "paper paper NOUN NN dobj xxxx True False\n",
            "at at ADP IN prep xx True True\n",
            "National National PROPN NNP nmod Xxxxx True False\n",
            "\n",
            "  \n",
            "  SPACE _SP  \n",
            "  False False\n",
            "visualization visualization NOUN NN pobj xxxx True False\n",
            ", , PUNCT , punct , False False\n",
            "i.e. i.e. X FW advmod x.x. False False\n",
            ", , PUNCT , punct , False False\n",
            "more more ADV RBR advmod xxxx True True\n",
            "- - PUNCT HYPH punct - False False\n",
            "understandable understandable ADJ JJ advcl xxxx True False\n",
            ", , PUNCT , punct , False False\n",
            "and and CCONJ CC cc xxx True True\n",
            "presentable presentable ADJ JJ conj xxxx True False\n",
            ". . PUNCT . punct . False False\n",
            "                                                              SPACE _SP       False False\n",
            "Conference Conference PROPN NNP ROOT Xxxxx True False\n",
            "on on ADP IN prep xx True True\n",
            "Bio Bio PROPN NNP compound Xxx True False\n",
            "- - PUNCT HYPH punct - False False\n",
            "diversity diversity NOUN NN pobj xxxx True False\n",
            ", , PUNCT , punct , False False\n",
            "\n",
            "                                                                                            \n",
            "                                                                                            SPACE _SP  \n",
            "     False False\n",
            "Ecosystem Ecosystem PROPN NNP conj Xxxxx True False\n",
            "and and CCONJ CC cc xxx True True\n",
            "Climatic Climatic PROPN NNP compound Xxxxx True False\n",
            "Change Change PROPN NNP conj Xxxxx True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "FACE face NOUN NN compound XXXX True False\n",
            "RECOGNITION recognition NOUN NN ROOT XXXX True False\n",
            "                                                                    SPACE _SP       False False\n",
            "[ [ PUNCT -LRB- punct [ False False\n",
            "Open Open PROPN NNP compound Xxxx True False\n",
            "- - PUNCT HYPH punct - False False\n",
            "CV CV PROPN NNP nmod XX True False\n",
            ", , PUNCT , punct , False False\n",
            "Python Python PROPN NNP ROOT Xxxxx True False\n",
            "] ] PUNCT -RRB- punct ] False False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "Description description NOUN NN dep Xxxxx True False\n",
            ": : PUNCT : punct : False False\n",
            "This this DET DT nsubj Xxxx True True\n",
            "is be AUX VBZ ROOT xx True True\n",
            "an an DET DT det xx True True\n",
            "ideal ideal ADJ JJ amod xxxx True False\n",
            "way way NOUN NN attr xxx True False\n",
            "of of ADP IN prep xx True True\n",
            "detecting detect VERB VBG pcomp xxxx True False\n",
            "and and CCONJ CC cc xxx True True\n",
            "recognizing recognize VERB VBG conj xxxx True False\n",
            "human human ADJ JJ amod xxxx True False\n",
            "face face NOUN NN dobj xxxx True False\n",
            "\n",
            " \n",
            " SPACE _SP  \n",
            " False False\n",
            "using use VERB VBG conj xxxx True True\n",
            "OpenCV OpenCV PROPN NNP dobj XxxxXX True False\n",
            ", , PUNCT , punct , False False\n",
            "and and CCONJ CC cc xxx True True\n",
            "python python PROPN NNP conj xxxx True False\n",
            "which which DET WDT nsubj xxxx True True\n",
            "is be AUX VBZ relcl xx True True\n",
            "part part NOUN NN attr xxxx True True\n",
            "of of ADP IN prep xx True True\n",
            "deep deep ADJ JJ amod xxxx True False\n",
            "learning learning NOUN NN pobj xxxx True False\n",
            "in in ADP IN prep xx True True\n",
            "real real ADJ JJ amod xxxx True False\n",
            "time time NOUN NN pobj xxxx True False\n",
            ". . PUNCT . punct . False False\n"
          ]
        }
      ]
    }
  ]
}