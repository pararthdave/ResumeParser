{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resume_parser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMv8uITyuus1EitY9QJQkf1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pararthdave/ResumeParser/blob/yogapriya/Resume_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lq6tnwc8nP8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6775a75-0c49-4147-a3a8-ad606316607a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.1.0-py3-none-any.whl (958 kB)\n",
            "\u001b[K     |████████████████████████████████| 958 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.19.0-py3-none-any.whl (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 40.6 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure]~=1.26\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 49.1 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 36.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.8 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-36.0.1 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.0 sniffio-1.2.0 trio-0.19.0 trio-websocket-0.9.2 urllib3-1.26.8 wsproto-1.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypdf2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuQLWLTV_VM4",
        "outputId": "6ac6bdaa-2201-4914-bce2-d063678d1175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.7/dist-packages (1.26.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        " \n",
        "pdfFileObject = open(r\"/content/priyanka_resume(8).pdf\", 'rb')\n",
        " \n",
        "pdfReader = PyPDF2.PdfFileReader(pdfFileObject)\n",
        " \n",
        "print(\" No. Of Pages :\", pdfReader.numPages)\n",
        " \n",
        "pageObject = pdfReader.getPage(0)\n",
        " \n",
        "print(pageObject.extractText())\n",
        "\n",
        "pdfFileObject.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgi4OI5v_bTm",
        "outputId": "9117dbfb-444b-4d8b-eb97-743ce94797a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " No. Of Pages : 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rd\n",
            "Sem\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CGPA\n",
            ":9\n",
            ":\n",
            "12\n",
            "\n",
            "\n",
            "\n",
            "Percentage\n",
            ":71\n",
            ":\n",
            "33\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CGPA\n",
            ":8\n",
            ":\n",
            "0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0dMQXOLCeSj",
        "outputId": "ed6e4db6-989f-4555-9fbf-53e3b6ef352c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.8.tar.gz (14 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14070 sha256=b51e05dbcc41df0b5b5182ebce830809ffb4174bc64e8e49624da927607ad13e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/89/b9/3f11250225d0f90e5454fcc30fd1b7208db226850715aa9ace\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPiF_zasCkNu",
        "outputId": "29e311fc-e0a0-4140-d32b-ac8040a98511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.16.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pdf2image) (7.1.2)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tika"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTIFz1b2DGSi",
        "outputId": "70713895-bf44-43f1-c897-dab6f1d080a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tika\n",
            "  Downloading tika-1.24.tar.gz (28 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (57.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2021.10.8)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 9.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-py3-none-any.whl size=32893 sha256=b2f89b1f2085e978d71a6257e52b40386b1bac1394832f783969b77cfac45687\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/2b/38/58ff05467a742e32f67f5d0de048fa046e764e2fbb25ac93f3\n",
            "Successfully built tika\n",
            "Installing collected packages: urllib3, tika\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.8\n",
            "    Uninstalling urllib3-1.26.8:\n",
            "      Successfully uninstalled urllib3-1.26.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "selenium 4.1.0 requires urllib3[secure]~=1.26, but you have urllib3 1.25.11 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed tika-1.24 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tika import parser # pip install tika\n",
        "\n",
        "raw = parser.from_file('/content/priyanka_resume(8).pdf')\n",
        "print(raw['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqnDRddZCpzH",
        "outputId": "2104230d-ec43-4c27-d015-a580fec0416b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Priyanka Raikwar\n",
            "priyanka.mnnit2020@gmail.com | +91-7974849362\n",
            "\n",
            "HouseNo.:33,Shivasthalicolony,Makroniya,Sagar | M.P, India\n",
            "\n",
            "EDUCATION\n",
            "MNNIT ALLAHABAD\n",
            "MASTERS OF COMPUTER\n",
            "APPLICATION\n",
            "Expected June 2022\n",
            "CPI: 8.6 ( Till 3rdSem)\n",
            "\n",
            "DR.HARISINGHGOUR\n",
            "UNIVERSITY, SAGAR\n",
            "BACHELOR OF COMPUTER\n",
            "APPLICATION\n",
            "June 2018\n",
            "CGPA : 9.12\n",
            "\n",
            "CLASS XII | CBSE\n",
            "D.M.A MAKRONIYA, SAGAR\n",
            "June 2015\n",
            "Percentage : 71.33%\n",
            "\n",
            "CLASS X | CBSE\n",
            "D.M.A MAKRONIYA, SAGAR\n",
            "June 2013\n",
            "CGPA : 8.0\n",
            "\n",
            "LINKS\n",
            "LinkedIn:// priyanka-raikwar-73a809152\n",
            "Hackerrank:// Priyankajma17\n",
            "\n",
            "AREAOF INTEREST\n",
            "•Data Structures and Algorithms\n",
            "•DBMS\n",
            "•Operating System\n",
            "•Competitive Coding\n",
            "\n",
            "SKILLS\n",
            "PROGRAMMING\n",
            "Familiar with:\n",
            "C/C++ •MySQL\n",
            "Basics:\n",
            "• Java •MongoDB\n",
            "•HTML •Python\n",
            "\n",
            "TECHNICAL\n",
            "Familiar with:\n",
            "• Android Studio • Netbeans\n",
            "• Anaconda\n",
            "• Visual Studio • Postman\n",
            "\n",
            "CAREEROBJECTIVE\n",
            "Toworkhardwith full dedication for achievementof organizationsobjectiveunder sat-\n",
            "isfying job contact,hence enhancing my skills and knowledge.\n",
            "\n",
            "PROJECTS\n",
            "LIBRARYMANAGEMENT SYSTEM | JAVA / SWING\n",
            "July 2020 – August 2020 | Java, MySQL\n",
            "\n",
            "• Login students with username and password.\n",
            "• Can add books in database to issue them.\n",
            "• Can add students and see their details of number of book issued and returned.\n",
            "• Can check statistics of issued and returned book.\n",
            "• Calculate fine for returning book late.\n",
            "\n",
            "HANDMOVEMENTDETECTION |PYTHON\n",
            "March 2021 – May 2021 | Computer Vision | Image Processing\n",
            "\n",
            "• Using Anaconda platform.\n",
            "• Libraries used are OpenCV andNumPy\n",
            "• Web camera will detect the hands gesture and respond corresponding to it.\n",
            "• Operation included are Pause, play, volume up, volume down and fast forward.\n",
            "\n",
            "FINDVACCINATION SLOT |PYTHON |JASON\n",
            "May 2021 | Using Setu API\n",
            "\n",
            "• Using Pycharm platform and Postman.\n",
            "• Can check vaccinations slots by PIN code and date.\n",
            "\n",
            "ACHIEVEMENTS & AWARDS\n",
            "July 2020 Certificate of Completion of ”Certified Network Security Specialist” by (ICSI)\n",
            "\n",
            "2017 Worked as Class Representative in BCA\n",
            "2017 Got second position in National Science Day Event\n",
            "\n",
            "EXTRACURRICULUMACTIVITY\n",
            "2019 Member of Volleyball team atMNNIT Allahabad\n",
            "2019 Got gold medal in kabaddi.\n",
            "\n",
            "HOBBIES\n",
            "• To explore and read about new technologies.\n",
            "• To read chronicles of freedom fighters\n",
            "• Drawing and Sketching\n",
            "\n",
            "1\n",
            "\n",
            "mailto:priyanka.mnnit2020@gmail.com\n",
            "tel: 7974849362\n",
            "House No.: 33, Shivasthali colony, Makroniya,Sagar\n",
            "https://www.linkedin.com/in/priyanka-raikwar-73a809152\n",
            "https://www.hackerrank.com/Priyankajma17\n",
            "\n",
            "\tEducation\n",
            "\tMNNIT ALLAHABAD\n",
            "\tDr.Harisingh Gour  University, Sagar\n",
            "\n",
            "\tLinks\n",
            "\tArea of Interest\n",
            "\tSkills\n",
            "\tProgramming\n",
            "\tTechnical\n",
            "\n",
            "\tCAREER OBJECTIVE\n",
            "\tPROJECTS\n",
            "\tAchievements & Awards\n",
            "\tExtra curriculum activity\n",
            "\t Hobbies\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download()\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C5apHagIORA",
        "outputId": "ed72382f-ccb1-4502-d9fa-45050c8f7ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "Hit Enter to continue: \n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "Hit Enter to continue: \n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw-1.4............. Open Multilingual Wordnet\n",
            "  [ ] omw................. Open Multilingual Wordnet\n",
            "  [ ] opinion_lexicon..... Opinion Lexicon\n",
            "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
            "  [ ] paradigms........... Paradigm Corpus\n",
            "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
            "                           Evaluation Shared Task\n",
            "Hit Enter to continue: \n",
            "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
            "                           character properties in Perl\n",
            "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
            "  [ ] pl196x.............. Polish language of the XX century sixties\n",
            "  [ ] porter_test......... Porter Stemmer Test Files\n",
            "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
            "  [ ] problem_reports..... Problem Report Corpus\n",
            "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
            "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
            "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
            "  [ ] pros_cons........... Pros and Cons\n",
            "  [ ] ptb................. Penn Treebank\n",
            "  [ ] qc.................. Experimental Data for Question Classification\n",
            "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
            "                           version\n",
            "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
            "                           Portuguesa)\n",
            "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
            "  [ ] sample_grammars..... Sample Grammars\n",
            "  [ ] semcor.............. SemCor 3.0\n",
            "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
            "Hit Enter to continue: \n",
            "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
            "  [ ] sentiwordnet........ SentiWordNet\n",
            "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
            "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
            "  [ ] smultron............ SMULTRON Corpus Sample\n",
            "  [ ] snowball_data....... Snowball Data\n",
            "  [ ] spanish_grammars.... Grammars for Spanish\n",
            "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
            "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
            "  [ ] swadesh............. Swadesh Wordlists\n",
            "  [ ] switchboard......... Switchboard Corpus Sample\n",
            "  [ ] tagsets............. Help on Tagsets\n",
            "  [ ] timit............... TIMIT Corpus Sample\n",
            "  [ ] toolbox............. Toolbox Sample Files\n",
            "  [ ] treebank............ Penn Treebank Sample\n",
            "  [ ] twitter_samples..... Twitter Samples\n",
            "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
            "                           (Unicode Version)\n",
            "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
            "  [ ] unicode_samples..... Unicode Samples\n",
            "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
            "Hit Enter to continue: \n",
            "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
            "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
            "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
            "  [ ] webtext............. Web Text Corpus\n",
            "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
            "  [ ] word2vec_sample..... Word2Vec Sample\n",
            "  [ ] wordnet2021......... Open English Wordnet 2021\n",
            "  [ ] wordnet31........... Wordnet 3.1\n",
            "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
            "  [ ] words............... Word Lists\n",
            "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
            "                           English Prose\n",
            "\n",
            "Collections:\n",
            "  [P] all-corpora......... All the corpora\n",
            "  [P] all-nltk............ All packages available on nltk_data gh-pages\n",
            "                           branch\n",
            "  [P] all................. All packages\n",
            "  [P] book................ Everything used in the NLTK Book\n",
            "  [P] popular............. Popular packages\n",
            "  [P] tests............... Packages for running tests\n",
            "  [ ] third-party......... Third-party data packages\n",
            "Hit Enter to continue: \n",
            "\n",
            "([*] marks installed packages; [P] marks partially installed collections)\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all-nltk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading collection 'all-nltk'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Unzipping corpora/abc.zip.\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Unzipping corpora/alpino.zip.\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package averaged_perceptron_tagger is already up-to-date!\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/basque_grammars.zip.\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Unzipping corpora/biocreative_ppi.zip.\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/book_grammars.zip.\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Package brown is already up-to-date!\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown_tei.zip.\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_cat.zip.\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_esp.zip.\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Unzipping corpora/chat80.zip.\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Unzipping corpora/city_database.zip.\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/comparative_sentences.zip.\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2000.zip.\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2002.zip.\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Unzipping corpora/crubadan.zip.\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/dependency_treebank.zip.\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Unzipping corpora/dolch.zip.\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Unzipping corpora/europarl_raw.zip.\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Unzipping corpora/floresta.zip.\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v15.zip.\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v17.zip.\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Unzipping corpora/gazetteers.zip.\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Unzipping corpora/ieer.zip.\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Unzipping corpora/indian.zip.\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Unzipping corpora/kimmo.zip.\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/large_grammars.zip.\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Unzipping corpora/lin_thesaurus.zip.\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Unzipping corpora/mac_morpho.zip.\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Package maxent_ne_chunker is already up-to-date!\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Unzipping models/moses_sample.zip.\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Unzipping corpora/mte_teip5.zip.\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Unzipping misc/mwa_ppdb.zip.\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Unzipping corpora/nps_chat.zip.\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       |   Unzipping corpora/omw.zip.\n",
            "       | Downloading package omw-1.4 to /root/nltk_data...\n",
            "       |   Unzipping corpora/omw-1.4.zip.\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Unzipping corpora/opinion_lexicon.zip.\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Unzipping corpora/paradigms.zip.\n",
            "       | Downloading package pe08 to /root/nltk_data...\n",
            "       |   Unzipping corpora/pe08.zip.\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Unzipping misc/perluniprops.zip.\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Unzipping corpora/pil.zip.\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Unzipping corpora/pl196x.zip.\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Unzipping stemmers/porter_test.zip.\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Unzipping corpora/ppattach.zip.\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Unzipping corpora/problem_reports.zip.\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_1.zip.\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_2.zip.\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Unzipping corpora/pros_cons.zip.\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Unzipping corpora/ptb.zip.\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Package punkt is already up-to-date!\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Unzipping corpora/qc.zip.\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Unzipping stemmers/rslp.zip.\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Unzipping corpora/rte.zip.\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/sample_grammars.zip.\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Unzipping corpora/senseval.zip.\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentence_polarity.zip.\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentiwordnet.zip.\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Unzipping corpora/shakespeare.zip.\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/sinica_treebank.zip.\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Unzipping corpora/smultron.zip.\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/spanish_grammars.zip.\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Unzipping corpora/state_union.zip.\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Package stopwords is already up-to-date!\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Unzipping corpora/subjectivity.zip.\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Unzipping corpora/swadesh.zip.\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Unzipping corpora/switchboard.zip.\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Unzipping help/tagsets.zip.\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Unzipping corpora/timit.zip.\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Unzipping corpora/toolbox.zip.\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/twitter_samples.zip.\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr.zip.\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr2.zip.\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/unicode_samples.zip.\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Package universal_tagset is already up-to-date!\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet.zip.\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet3.zip.\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Unzipping corpora/webtext.zip.\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Unzipping models/wmt15_eval.zip.\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Unzipping models/word2vec_sample.zip.\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       |   Package wordnet is already up-to-date!\n",
            "       | Downloading package wordnet2021 to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet2021.zip.\n",
            "       | Downloading package wordnet31 to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet31.zip.\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Unzipping corpora/ycoe.zip.\n",
            "       | \n",
            "     Done downloading collection all-nltk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# word_tokenize accepts\n",
        "# a string as an input, not a file.\n",
        "stop_words = set(stopwords.words('english'))\n",
        "file1 = raw['content']\n",
        "# Use this to read file content as a stream:\n",
        "\n",
        "words = file1.split()\n",
        "for r in words:\n",
        "\tif not r in stop_words:\n",
        "\t\tappendFile = open('filteredtext.txt','a')\n",
        "\t\tappendFile.write(\" \"+r)\n",
        "\t\tappendFile.close()\n"
      ],
      "metadata": {
        "id": "sfnte5GTIijg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#python -m spacy download en_core_web_md\n",
        "#python -m spacy link en_core_web_md en\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh6tvpiyK9qF",
        "outputId": "cbc11af3-0db0-488c-9b91-b890d569d464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate [util.py:275]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = spacy.load('en_core_web_sm', disable = ['parser','ner'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6cOZeynK1YT",
        "outputId": "8363d3da-5988-42bd-b00d-712bbc86824b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate [util.py:275]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "doc = load_model('/content/filteredtext.txt')\n"
      ],
      "metadata": {
        "id": "wgRNvjUHKaYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\" \".join([token.lemma_ for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BXTgndnoLg-V",
        "outputId": "139fbcbd-87e8-4326-cf9a-d075b8ac18d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content / filteredtext.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/filteredtext.txt'\n",
        "introduction_file_text = open(file_name).read()\n",
        "introduction_file_doc = nlp(introduction_file_text)\n",
        " # Extract tokens for the given doc\n",
        "print ([token.text for token in introduction_file_doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tke4MTM2LjXi",
        "outputId": "4a9b2e6d-f314-4965-e53a-d18339542528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', 'Priyanka', 'Raikwar', 'priyanka.mnnit2020@gmail.com', '|', '+91', '-', '7974849362', 'HouseNo.:33,Shivasthalicolony', ',', 'Makroniya', ',', 'Sagar', '|', 'M.P', ',', 'India', 'EDUCATION', 'MNNIT', 'ALLAHABAD', 'MASTERS', 'OF', 'COMPUTER', 'APPLICATION', 'Expected', 'June', '2022', 'CPI', ':', '8.6', '(', 'Till', '3rdSem', ')', 'DR.HARISINGHGOUR', 'UNIVERSITY', ',', 'SAGAR', 'BACHELOR', 'OF', 'COMPUTER', 'APPLICATION', 'June', '2018', 'CGPA', ':', '9.12', 'CLASS', 'XII', '|', 'CBSE', 'D.M.A', 'MAKRONIYA', ',', 'SAGAR', 'June', '2015', 'Percentage', ':', '71.33', '%', 'CLASS', 'X', '|', 'CBSE', 'D.M.A', 'MAKRONIYA', ',', 'SAGAR', 'June', '2013', 'CGPA', ':', '8.0', 'LINKS', 'LinkedIn://', 'priyanka', '-', 'raikwar-73a809152', 'Hackerrank://', 'Priyankajma17', 'AREAOF', 'INTEREST', '•Data', 'Structures', 'Algorithms', '•DBMS', '•Operating', 'System', '•Competitive', 'Coding', 'SKILLS', 'PROGRAMMING', 'Familiar', 'with', ':', 'C', '/', 'C++', '•MySQL', 'Basics', ':', '•', 'Java', '•MongoDB', '•HTML', '•Python', 'TECHNICAL', 'Familiar', 'with', ':', '•', 'Android', 'Studio', '•', 'Netbeans', '•', 'Anaconda', '•', 'Visual', 'Studio', '•', 'Postman', 'CAREEROBJECTIVE', 'Toworkhardwith', 'full', 'dedication', 'achievementof', 'organizationsobjectiveunder', 'sat-', 'isfying', 'job', 'contact', ',', 'hence', 'enhancing', 'skills', 'knowledge', '.', 'PROJECTS', 'LIBRARYMANAGEMENT', 'SYSTEM', '|', 'JAVA', '/', 'SWING', 'July', '2020', '–', 'August', '2020', '|', 'Java', ',', 'MySQL', '•', 'Login', 'students', 'username', 'password', '.', '•', 'Can', 'add', 'books', 'database', 'issue', 'them', '.', '•', 'Can', 'add', 'students', 'see', 'details', 'number', 'book', 'issued', 'returned', '.', '•', 'Can', 'check', 'statistics', 'issued', 'returned', 'book', '.', '•', 'Calculate', 'fine', 'returning', 'book', 'late', '.', 'HANDMOVEMENTDETECTION', '|PYTHON', 'March', '2021', '–', 'May', '2021', '|', 'Computer', 'Vision', '|', 'Image', 'Processing', '•', 'Using', 'Anaconda', 'platform', '.', '•', 'Libraries', 'used', 'OpenCV', 'andNumPy', '•', 'Web', 'camera', 'detect', 'hands', 'gesture', 'respond', 'corresponding', 'it', '.', '•', 'Operation', 'included', 'Pause', ',', 'play', ',', 'volume', 'up', ',', 'volume', 'fast', 'forward', '.', 'FINDVACCINATION', 'SLOT', '|PYTHON', '|JASON', 'May', '2021', '|', 'Using', 'Setu', 'API', '•', 'Using', 'Pycharm', 'platform', 'Postman', '.', '•', 'Can', 'check', 'vaccinations', 'slots', 'PIN', 'code', 'date', '.', 'ACHIEVEMENTS', '&', 'AWARDS', 'July', '2020', 'Certificate', 'Completion', '”', 'Certified', 'Network', 'Security', 'Specialist', '”', '(', 'ICSI', ')', '2017', 'Worked', 'Class', 'Representative', 'BCA', '2017', 'Got', 'second', 'position', 'National', 'Science', 'Day', 'Event', 'EXTRACURRICULUMACTIVITY', '2019', 'Member', 'Volleyball', 'team', 'atMNNIT', 'Allahabad', '2019', 'Got', 'gold', 'medal', 'kabaddi', '.', 'HOBBIES', '•', 'To', 'explore', 'read', 'new', 'technologies', '.', '•', 'To', 'read', 'chronicles', 'freedom', 'fighters', '•', 'Drawing', 'Sketching', '1', 'mailto:priyanka.mnnit2020@gmail.com', 'tel', ':', '7974849362', 'House', 'No', '.', ':', '33', ',', 'Shivasthali', 'colony', ',', 'Makroniya', ',', 'Sagar', 'https://www.linkedin.com/in/priyanka-raikwar-73a809152', 'https://www.hackerrank.com/Priyankajma17', 'Education', 'MNNIT', 'ALLAHABAD', 'Dr', '.', 'Harisingh', 'Gour', 'University', ',', 'Sagar', 'Links', 'Area', 'Interest', 'Skills', 'Programming', 'Technical', 'CAREER', 'OBJECTIVE', 'PROJECTS', 'Achievements', '&', 'Awards', 'Extra', 'curriculum', 'activity', 'Hobbies']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "about_text = '/content/filteredtext.txt'\n",
        "introduction_file_text = open(about_text).read()\n",
        "about_doc = nlp(introduction_file_text)\n",
        "sentences = list(about_doc.sents)\n",
        "len(sentences)\n",
        "\n",
        "for sentence in sentences:\n",
        "     print (sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPGfyBbvL81z",
        "outputId": "3bc78d8b-d33b-4a20-e8a9-c094a5b02c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Priyanka Raikwar priyanka.mnnit2020@gmail.com | +91-7974849362 HouseNo.:33,Shivasthalicolony,Makroniya,Sagar | M.P, India EDUCATION MNNIT ALLAHABAD MASTERS OF COMPUTER APPLICATION\n",
            "Expected June 2022 CPI: 8.6\n",
            "( Till 3rdSem) DR.HARISINGHGOUR UNIVERSITY, SAGAR BACHELOR OF COMPUTER APPLICATION June 2018 CGPA : 9.12 CLASS XII\n",
            "| CBSE D.M.A MAKRONIYA, SAGAR June 2015 Percentage : 71.33% CLASS X |\n",
            "CBSE D.M.A MAKRONIYA, SAGAR June 2013 CGPA : 8.0 LINKS LinkedIn:// priyanka-raikwar-73a809152\n",
            "Hackerrank:// Priyankajma17\n",
            "AREAOF INTEREST •Data Structures Algorithms\n",
            "•DBMS •Operating System •Competitive Coding SKILLS PROGRAMMING Familiar with: C/C++ •MySQL Basics:\n",
            "• Java •MongoDB\n",
            "•HTML •Python TECHNICAL Familiar with:\n",
            "•\n",
            "Android Studio\n",
            "• Netbeans\n",
            "•\n",
            "Anaconda • Visual Studio\n",
            "• Postman CAREEROBJECTIVE\n",
            "Toworkhardwith full dedication\n",
            "achievementof organizationsobjectiveunder sat- isfying job contact,\n",
            "hence enhancing skills knowledge.\n",
            "PROJECTS LIBRARYMANAGEMENT SYSTEM\n",
            "|\n",
            "JAVA / SWING July 2020 – August 2020\n",
            "| Java, MySQL • Login students username password.\n",
            "• Can add books database issue them.\n",
            "• Can add students see details number book issued returned.\n",
            "• Can check statistics issued returned book.\n",
            "• Calculate fine returning book late.\n",
            "HANDMOVEMENTDETECTION\n",
            "|PYTHON\n",
            "March 2021 – May 2021\n",
            "|\n",
            "Computer Vision\n",
            "|\n",
            "Image Processing • Using Anaconda platform.\n",
            "• Libraries used OpenCV andNumPy\n",
            "• Web camera detect hands\n",
            "gesture respond corresponding it.\n",
            "•\n",
            "Operation included Pause, play, volume up, volume fast forward.\n",
            "FINDVACCINATION SLOT |PYTHON\n",
            "|JASON\n",
            "May 2021 |\n",
            "Using Setu API •\n",
            "Using Pycharm platform Postman.\n",
            "• Can check vaccinations slots PIN code date.\n",
            "ACHIEVEMENTS & AWARDS July 2020 Certificate Completion ”Certified Network Security Specialist” (ICSI)\n",
            "2017 Worked Class Representative BCA 2017 Got second position National Science Day Event\n",
            "EXTRACURRICULUMACTIVITY 2019 Member Volleyball team atMNNIT\n",
            "Allahabad 2019 Got gold medal kabaddi.\n",
            "HOBBIES •\n",
            "To explore read new technologies.\n",
            "•\n",
            "To read chronicles freedom fighters\n",
            "•\n",
            "Drawing\n",
            "Sketching\n",
            "1 mailto:priyanka.mnnit2020@gmail.com tel:\n",
            "7974849362 House\n",
            "No.: 33, Shivasthali colony, Makroniya,Sagar https://www.linkedin.com/in/priyanka-raikwar-73a809152 https://www.hackerrank.com/Priyankajma17 Education MNNIT ALLAHABAD Dr.\n",
            "Harisingh Gour University, Sagar Links Area\n",
            "Interest Skills Programming Technical CAREER OBJECTIVE PROJECTS Achievements & Awards Extra curriculum activity Hobbies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in about_doc:\n",
        "  print (token, token.idx, token.text_with_ws,\n",
        "          token.is_alpha, token.is_punct, token.is_space,\n",
        "            token.shape_, token.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kInI2BH6MPVn",
        "outputId": "c22d8bfb-d664-453e-da31-709008156050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0   False False True   False\n",
            "Priyanka 1 Priyanka  True False False Xxxxx False\n",
            "Raikwar 10 Raikwar  True False False Xxxxx False\n",
            "priyanka.mnnit2020@gmail.com 18 priyanka.mnnit2020@gmail.com  False False False xxxx.xxxxdddd@xxxx.xxx False\n",
            "| 47 |  False False False | False\n",
            "+91 49 +91 False False False +dd False\n",
            "- 52 - False True False - False\n",
            "7974849362 53 7974849362  False False False dddd False\n",
            "HouseNo.:33,Shivasthalicolony 64 HouseNo.:33,Shivasthalicolony False False False XxxxxXx.:dd,Xxxxx False\n",
            ", 93 , False True False , False\n",
            "Makroniya 94 Makroniya True False False Xxxxx False\n",
            ", 103 , False True False , False\n",
            "Sagar 104 Sagar  True False False Xxxxx False\n",
            "| 110 |  False False False | False\n",
            "M.P 112 M.P False False False X.X False\n",
            ", 115 ,  False True False , False\n",
            "India 117 India  True False False Xxxxx False\n",
            "EDUCATION 123 EDUCATION  True False False XXXX False\n",
            "MNNIT 133 MNNIT  True False False XXXX False\n",
            "ALLAHABAD 139 ALLAHABAD  True False False XXXX False\n",
            "MASTERS 149 MASTERS  True False False XXXX False\n",
            "OF 157 OF  True False False XX True\n",
            "COMPUTER 160 COMPUTER  True False False XXXX False\n",
            "APPLICATION 169 APPLICATION  True False False XXXX False\n",
            "Expected 181 Expected  True False False Xxxxx False\n",
            "June 190 June  True False False Xxxx False\n",
            "2022 195 2022  False False False dddd False\n",
            "CPI 200 CPI True False False XXX False\n",
            ": 203 :  False True False : False\n",
            "8.6 205 8.6  False False False d.d False\n",
            "( 209 (  False True False ( False\n",
            "Till 211 Till  True False False Xxxx False\n",
            "3rdSem 216 3rdSem False False False dxxXxx False\n",
            ") 222 )  False True False ) False\n",
            "DR.HARISINGHGOUR 224 DR.HARISINGHGOUR  False False False XX.XXXX False\n",
            "UNIVERSITY 241 UNIVERSITY True False False XXXX False\n",
            ", 251 ,  False True False , False\n",
            "SAGAR 253 SAGAR  True False False XXXX False\n",
            "BACHELOR 259 BACHELOR  True False False XXXX False\n",
            "OF 268 OF  True False False XX True\n",
            "COMPUTER 271 COMPUTER  True False False XXXX False\n",
            "APPLICATION 280 APPLICATION  True False False XXXX False\n",
            "June 292 June  True False False Xxxx False\n",
            "2018 297 2018  False False False dddd False\n",
            "CGPA 302 CGPA  True False False XXXX False\n",
            ": 307 :  False True False : False\n",
            "9.12 309 9.12  False False False d.dd False\n",
            "CLASS 314 CLASS  True False False XXXX False\n",
            "XII 320 XII  True False False XXX False\n",
            "| 324 |  False False False | False\n",
            "CBSE 326 CBSE  True False False XXXX False\n",
            "D.M.A 331 D.M.A  False False False X.X.X False\n",
            "MAKRONIYA 337 MAKRONIYA True False False XXXX False\n",
            ", 346 ,  False True False , False\n",
            "SAGAR 348 SAGAR  True False False XXXX False\n",
            "June 354 June  True False False Xxxx False\n",
            "2015 359 2015  False False False dddd False\n",
            "Percentage 364 Percentage  True False False Xxxxx False\n",
            ": 375 :  False True False : False\n",
            "71.33 377 71.33 False False False dd.dd False\n",
            "% 382 %  False True False % False\n",
            "CLASS 384 CLASS  True False False XXXX False\n",
            "X 390 X  True False False X False\n",
            "| 392 |  False False False | False\n",
            "CBSE 394 CBSE  True False False XXXX False\n",
            "D.M.A 399 D.M.A  False False False X.X.X False\n",
            "MAKRONIYA 405 MAKRONIYA True False False XXXX False\n",
            ", 414 ,  False True False , False\n",
            "SAGAR 416 SAGAR  True False False XXXX False\n",
            "June 422 June  True False False Xxxx False\n",
            "2013 427 2013  False False False dddd False\n",
            "CGPA 432 CGPA  True False False XXXX False\n",
            ": 437 :  False True False : False\n",
            "8.0 439 8.0  False False False d.d False\n",
            "LINKS 443 LINKS  True False False XXXX False\n",
            "LinkedIn:// 449 LinkedIn://  False False False XxxxxXx:// False\n",
            "priyanka 461 priyanka True False False xxxx False\n",
            "- 469 - False True False - False\n",
            "raikwar-73a809152 470 raikwar-73a809152  False False False xxxx-ddxdddd False\n",
            "Hackerrank:// 488 Hackerrank://  False False False Xxxxx:// False\n",
            "Priyankajma17 502 Priyankajma17  False False False Xxxxxdd False\n",
            "AREAOF 516 AREAOF  True False False XXXX False\n",
            "INTEREST 523 INTEREST  True False False XXXX False\n",
            "•Data 532 •Data  False False False •Xxxx False\n",
            "Structures 538 Structures  True False False Xxxxx False\n",
            "Algorithms 549 Algorithms  True False False Xxxxx False\n",
            "•DBMS 560 •DBMS  False False False •XXXX False\n",
            "•Operating 566 •Operating  False False False •Xxxxx False\n",
            "System 577 System  True False False Xxxxx False\n",
            "•Competitive 584 •Competitive  False False False •Xxxxx False\n",
            "Coding 597 Coding  True False False Xxxxx False\n",
            "SKILLS 604 SKILLS  True False False XXXX False\n",
            "PROGRAMMING 611 PROGRAMMING  True False False XXXX False\n",
            "Familiar 623 Familiar  True False False Xxxxx False\n",
            "with 632 with True False False xxxx True\n",
            ": 636 :  False True False : False\n",
            "C 638 C True False False X False\n",
            "/ 639 / False True False / False\n",
            "C++ 640 C++  False False False X++ False\n",
            "•MySQL 644 •MySQL  False False False •XxXXX False\n",
            "Basics 651 Basics True False False Xxxxx False\n",
            ": 657 :  False True False : False\n",
            "• 659 •  False True False • False\n",
            "Java 661 Java  True False False Xxxx False\n",
            "•MongoDB 666 •MongoDB  False False False •XxxxxXX False\n",
            "•HTML 675 •HTML  False False False •XXXX False\n",
            "•Python 681 •Python  False False False •Xxxxx False\n",
            "TECHNICAL 689 TECHNICAL  True False False XXXX False\n",
            "Familiar 699 Familiar  True False False Xxxxx False\n",
            "with 708 with True False False xxxx True\n",
            ": 712 :  False True False : False\n",
            "• 714 •  False True False • False\n",
            "Android 716 Android  True False False Xxxxx False\n",
            "Studio 724 Studio  True False False Xxxxx False\n",
            "• 731 •  False True False • False\n",
            "Netbeans 733 Netbeans  True False False Xxxxx False\n",
            "• 742 •  False True False • False\n",
            "Anaconda 744 Anaconda  True False False Xxxxx False\n",
            "• 753 •  False True False • False\n",
            "Visual 755 Visual  True False False Xxxxx False\n",
            "Studio 762 Studio  True False False Xxxxx False\n",
            "• 769 •  False True False • False\n",
            "Postman 771 Postman  True False False Xxxxx False\n",
            "CAREEROBJECTIVE 779 CAREEROBJECTIVE  True False False XXXX False\n",
            "Toworkhardwith 795 Toworkhardwith  True False False Xxxxx False\n",
            "full 810 full  True False False xxxx True\n",
            "dedication 815 dedication  True False False xxxx False\n",
            "achievementof 826 achievementof  True False False xxxx False\n",
            "organizationsobjectiveunder 840 organizationsobjectiveunder  True False False xxxx False\n",
            "sat- 868 sat-  False False False xxx- False\n",
            "isfying 873 isfying  True False False xxxx False\n",
            "job 881 job  True False False xxx False\n",
            "contact 885 contact True False False xxxx False\n",
            ", 892 , False True False , False\n",
            "hence 893 hence  True False False xxxx True\n",
            "enhancing 899 enhancing  True False False xxxx False\n",
            "skills 909 skills  True False False xxxx False\n",
            "knowledge 916 knowledge True False False xxxx False\n",
            ". 925 .  False True False . False\n",
            "PROJECTS 927 PROJECTS  True False False XXXX False\n",
            "LIBRARYMANAGEMENT 936 LIBRARYMANAGEMENT  True False False XXXX False\n",
            "SYSTEM 954 SYSTEM  True False False XXXX False\n",
            "| 961 |  False False False | False\n",
            "JAVA 963 JAVA  True False False XXXX False\n",
            "/ 968 /  False True False / False\n",
            "SWING 970 SWING  True False False XXXX False\n",
            "July 976 July  True False False Xxxx False\n",
            "2020 981 2020  False False False dddd False\n",
            "– 986 –  False True False – False\n",
            "August 988 August  True False False Xxxxx False\n",
            "2020 995 2020  False False False dddd False\n",
            "| 1000 |  False False False | False\n",
            "Java 1002 Java True False False Xxxx False\n",
            ", 1006 ,  False True False , False\n",
            "MySQL 1008 MySQL  True False False XxXXX False\n",
            "• 1014 •  False True False • False\n",
            "Login 1016 Login  True False False Xxxxx False\n",
            "students 1022 students  True False False xxxx False\n",
            "username 1031 username  True False False xxxx False\n",
            "password 1040 password True False False xxxx False\n",
            ". 1048 .  False True False . False\n",
            "• 1050 •  False True False • False\n",
            "Can 1052 Can  True False False Xxx True\n",
            "add 1056 add  True False False xxx False\n",
            "books 1060 books  True False False xxxx False\n",
            "database 1066 database  True False False xxxx False\n",
            "issue 1075 issue  True False False xxxx False\n",
            "them 1081 them True False False xxxx True\n",
            ". 1085 .  False True False . False\n",
            "• 1087 •  False True False • False\n",
            "Can 1089 Can  True False False Xxx True\n",
            "add 1093 add  True False False xxx False\n",
            "students 1097 students  True False False xxxx False\n",
            "see 1106 see  True False False xxx True\n",
            "details 1110 details  True False False xxxx False\n",
            "number 1118 number  True False False xxxx False\n",
            "book 1125 book  True False False xxxx False\n",
            "issued 1130 issued  True False False xxxx False\n",
            "returned 1137 returned True False False xxxx False\n",
            ". 1145 .  False True False . False\n",
            "• 1147 •  False True False • False\n",
            "Can 1149 Can  True False False Xxx True\n",
            "check 1153 check  True False False xxxx False\n",
            "statistics 1159 statistics  True False False xxxx False\n",
            "issued 1170 issued  True False False xxxx False\n",
            "returned 1177 returned  True False False xxxx False\n",
            "book 1186 book True False False xxxx False\n",
            ". 1190 .  False True False . False\n",
            "• 1192 •  False True False • False\n",
            "Calculate 1194 Calculate  True False False Xxxxx False\n",
            "fine 1204 fine  True False False xxxx False\n",
            "returning 1209 returning  True False False xxxx False\n",
            "book 1219 book  True False False xxxx False\n",
            "late 1224 late True False False xxxx False\n",
            ". 1228 .  False True False . False\n",
            "HANDMOVEMENTDETECTION 1230 HANDMOVEMENTDETECTION  True False False XXXX False\n",
            "|PYTHON 1252 |PYTHON  False False False |XXXX False\n",
            "March 1260 March  True False False Xxxxx False\n",
            "2021 1266 2021  False False False dddd False\n",
            "– 1271 –  False True False – False\n",
            "May 1273 May  True False False Xxx True\n",
            "2021 1277 2021  False False False dddd False\n",
            "| 1282 |  False False False | False\n",
            "Computer 1284 Computer  True False False Xxxxx False\n",
            "Vision 1293 Vision  True False False Xxxxx False\n",
            "| 1300 |  False False False | False\n",
            "Image 1302 Image  True False False Xxxxx False\n",
            "Processing 1308 Processing  True False False Xxxxx False\n",
            "• 1319 •  False True False • False\n",
            "Using 1321 Using  True False False Xxxxx True\n",
            "Anaconda 1327 Anaconda  True False False Xxxxx False\n",
            "platform 1336 platform True False False xxxx False\n",
            ". 1344 .  False True False . False\n",
            "• 1346 •  False True False • False\n",
            "Libraries 1348 Libraries  True False False Xxxxx False\n",
            "used 1358 used  True False False xxxx True\n",
            "OpenCV 1363 OpenCV  True False False XxxxXX False\n",
            "andNumPy 1370 andNumPy  True False False xxxXxxXx False\n",
            "• 1379 •  False True False • False\n",
            "Web 1381 Web  True False False Xxx False\n",
            "camera 1385 camera  True False False xxxx False\n",
            "detect 1392 detect  True False False xxxx False\n",
            "hands 1399 hands  True False False xxxx False\n",
            "gesture 1405 gesture  True False False xxxx False\n",
            "respond 1413 respond  True False False xxxx False\n",
            "corresponding 1421 corresponding  True False False xxxx False\n",
            "it 1435 it True False False xx True\n",
            ". 1437 .  False True False . False\n",
            "• 1439 •  False True False • False\n",
            "Operation 1441 Operation  True False False Xxxxx False\n",
            "included 1451 included  True False False xxxx False\n",
            "Pause 1460 Pause True False False Xxxxx False\n",
            ", 1465 ,  False True False , False\n",
            "play 1467 play True False False xxxx False\n",
            ", 1471 ,  False True False , False\n",
            "volume 1473 volume  True False False xxxx False\n",
            "up 1480 up True False False xx True\n",
            ", 1482 ,  False True False , False\n",
            "volume 1484 volume  True False False xxxx False\n",
            "fast 1491 fast  True False False xxxx False\n",
            "forward 1496 forward True False False xxxx False\n",
            ". 1503 .  False True False . False\n",
            "FINDVACCINATION 1505 FINDVACCINATION  True False False XXXX False\n",
            "SLOT 1521 SLOT  True False False XXXX False\n",
            "|PYTHON 1526 |PYTHON  False False False |XXXX False\n",
            "|JASON 1534 |JASON  False False False |XXXX False\n",
            "May 1541 May  True False False Xxx True\n",
            "2021 1545 2021  False False False dddd False\n",
            "| 1550 |  False False False | False\n",
            "Using 1552 Using  True False False Xxxxx True\n",
            "Setu 1558 Setu  True False False Xxxx False\n",
            "API 1563 API  True False False XXX False\n",
            "• 1567 •  False True False • False\n",
            "Using 1569 Using  True False False Xxxxx True\n",
            "Pycharm 1575 Pycharm  True False False Xxxxx False\n",
            "platform 1583 platform  True False False xxxx False\n",
            "Postman 1592 Postman True False False Xxxxx False\n",
            ". 1599 .  False True False . False\n",
            "• 1601 •  False True False • False\n",
            "Can 1603 Can  True False False Xxx True\n",
            "check 1607 check  True False False xxxx False\n",
            "vaccinations 1613 vaccinations  True False False xxxx False\n",
            "slots 1626 slots  True False False xxxx False\n",
            "PIN 1632 PIN  True False False XXX False\n",
            "code 1636 code  True False False xxxx False\n",
            "date 1641 date True False False xxxx False\n",
            ". 1645 .  False True False . False\n",
            "ACHIEVEMENTS 1647 ACHIEVEMENTS  True False False XXXX False\n",
            "& 1660 &  False True False & False\n",
            "AWARDS 1662 AWARDS  True False False XXXX False\n",
            "July 1669 July  True False False Xxxx False\n",
            "2020 1674 2020  False False False dddd False\n",
            "Certificate 1679 Certificate  True False False Xxxxx False\n",
            "Completion 1691 Completion  True False False Xxxxx False\n",
            "” 1702 ” False True False ” False\n",
            "Certified 1703 Certified  True False False Xxxxx False\n",
            "Network 1713 Network  True False False Xxxxx False\n",
            "Security 1721 Security  True False False Xxxxx False\n",
            "Specialist 1730 Specialist True False False Xxxxx False\n",
            "” 1740 ”  False True False ” False\n",
            "( 1742 ( False True False ( False\n",
            "ICSI 1743 ICSI True False False XXXX False\n",
            ") 1747 )  False True False ) False\n",
            "2017 1749 2017  False False False dddd False\n",
            "Worked 1754 Worked  True False False Xxxxx False\n",
            "Class 1761 Class  True False False Xxxxx False\n",
            "Representative 1767 Representative  True False False Xxxxx False\n",
            "BCA 1782 BCA  True False False XXX False\n",
            "2017 1786 2017  False False False dddd False\n",
            "Got 1791 Got  True False False Xxx False\n",
            "second 1795 second  True False False xxxx False\n",
            "position 1802 position  True False False xxxx False\n",
            "National 1811 National  True False False Xxxxx False\n",
            "Science 1820 Science  True False False Xxxxx False\n",
            "Day 1828 Day  True False False Xxx False\n",
            "Event 1832 Event  True False False Xxxxx False\n",
            "EXTRACURRICULUMACTIVITY 1838 EXTRACURRICULUMACTIVITY  True False False XXXX False\n",
            "2019 1862 2019  False False False dddd False\n",
            "Member 1867 Member  True False False Xxxxx False\n",
            "Volleyball 1874 Volleyball  True False False Xxxxx False\n",
            "team 1885 team  True False False xxxx False\n",
            "atMNNIT 1890 atMNNIT  True False False xxXXXX False\n",
            "Allahabad 1898 Allahabad  True False False Xxxxx False\n",
            "2019 1908 2019  False False False dddd False\n",
            "Got 1913 Got  True False False Xxx False\n",
            "gold 1917 gold  True False False xxxx False\n",
            "medal 1922 medal  True False False xxxx False\n",
            "kabaddi 1928 kabaddi True False False xxxx False\n",
            ". 1935 .  False True False . False\n",
            "HOBBIES 1937 HOBBIES  True False False XXXX False\n",
            "• 1945 •  False True False • False\n",
            "To 1947 To  True False False Xx True\n",
            "explore 1950 explore  True False False xxxx False\n",
            "read 1958 read  True False False xxxx False\n",
            "new 1963 new  True False False xxx False\n",
            "technologies 1967 technologies True False False xxxx False\n",
            ". 1979 .  False True False . False\n",
            "• 1981 •  False True False • False\n",
            "To 1983 To  True False False Xx True\n",
            "read 1986 read  True False False xxxx False\n",
            "chronicles 1991 chronicles  True False False xxxx False\n",
            "freedom 2002 freedom  True False False xxxx False\n",
            "fighters 2010 fighters  True False False xxxx False\n",
            "• 2019 •  False True False • False\n",
            "Drawing 2021 Drawing  True False False Xxxxx False\n",
            "Sketching 2029 Sketching  True False False Xxxxx False\n",
            "1 2039 1  False False False d False\n",
            "mailto:priyanka.mnnit2020@gmail.com 2041 mailto:priyanka.mnnit2020@gmail.com  False False False xxxx:xxxx.xxxxdddd@xxxx.xxx False\n",
            "tel 2077 tel True False False xxx False\n",
            ": 2080 :  False True False : False\n",
            "7974849362 2082 7974849362  False False False dddd False\n",
            "House 2093 House  True False False Xxxxx False\n",
            "No 2099 No True False False Xx True\n",
            ". 2101 . False True False . False\n",
            ": 2102 :  False True False : False\n",
            "33 2104 33 False False False dd False\n",
            ", 2106 ,  False True False , False\n",
            "Shivasthali 2108 Shivasthali  True False False Xxxxx False\n",
            "colony 2120 colony True False False xxxx False\n",
            ", 2126 ,  False True False , False\n",
            "Makroniya 2128 Makroniya True False False Xxxxx False\n",
            ", 2137 , False True False , False\n",
            "Sagar 2138 Sagar  True False False Xxxxx False\n",
            "https://www.linkedin.com/in/priyanka-raikwar-73a809152 2144 https://www.linkedin.com/in/priyanka-raikwar-73a809152  False False False xxxx://xxx.xxxx.xxx/xx/xxxx-xxxx-ddxdddd False\n",
            "https://www.hackerrank.com/Priyankajma17 2199 https://www.hackerrank.com/Priyankajma17  False False False xxxx://xxx.xxxx.xxx/Xxxxxdd False\n",
            "Education 2240 Education  True False False Xxxxx False\n",
            "MNNIT 2250 MNNIT  True False False XXXX False\n",
            "ALLAHABAD 2256 ALLAHABAD  True False False XXXX False\n",
            "Dr 2266 Dr True False False Xx False\n",
            ". 2268 . False True False . False\n",
            "Harisingh 2269 Harisingh  True False False Xxxxx False\n",
            "Gour 2279 Gour  True False False Xxxx False\n",
            "University 2284 University True False False Xxxxx False\n",
            ", 2294 ,  False True False , False\n",
            "Sagar 2296 Sagar  True False False Xxxxx False\n",
            "Links 2302 Links  True False False Xxxxx False\n",
            "Area 2308 Area  True False False Xxxx False\n",
            "Interest 2313 Interest  True False False Xxxxx False\n",
            "Skills 2322 Skills  True False False Xxxxx False\n",
            "Programming 2329 Programming  True False False Xxxxx False\n",
            "Technical 2341 Technical  True False False Xxxxx False\n",
            "CAREER 2351 CAREER  True False False XXXX False\n",
            "OBJECTIVE 2358 OBJECTIVE  True False False XXXX False\n",
            "PROJECTS 2368 PROJECTS  True False False XXXX False\n",
            "Achievements 2377 Achievements  True False False Xxxxx False\n",
            "& 2390 &  False True False & False\n",
            "Awards 2392 Awards  True False False Xxxxx False\n",
            "Extra 2399 Extra  True False False Xxxxx False\n",
            "curriculum 2405 curriculum  True False False xxxx False\n",
            "activity 2416 activity  True False False xxxx False\n",
            "Hobbies 2425 Hobbies True False False Xxxxx False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "custom_nlp = spacy.load('en_core_web_sm')\n",
        "prefix_re = spacy.util.compile_prefix_regex(custom_nlp.Defaults.prefixes)\n",
        "suffix_re = spacy.util.compile_suffix_regex(custom_nlp.Defaults.suffixes)\n",
        "infix_re = re.compile(r'''[-~]''')\n",
        "def customize_tokenizer(nlp):\n",
        "    # Adds support to use `-` as the delimiter for tokenization\n",
        "    return Tokenizer(nlp.vocab, prefix_search=prefix_re.search,\n",
        "                     suffix_search=suffix_re.search,\n",
        "                     infix_finditer=infix_re.finditer,\n",
        "                     token_match=None\n",
        "                     )\n",
        "\n",
        "\n",
        "custom_nlp.tokenizer = customize_tokenizer(custom_nlp)\n",
        "custom_tokenizer_about_doc = custom_nlp(about_text)\n",
        "print([token.text for token in custom_tokenizer_about_doc])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngGeyaVpMsG5",
        "outputId": "a88103c4-6dbb-47fd-978b-c94b56f6dc11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UserWarning: [W031] Model 'en_core_web_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate [util.py:275]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/filteredtext.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "len(spacy_stopwords)\n",
        "\n",
        "for stop_word in list(spacy_stopwords)[:10]:\n",
        "    print(stop_word)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5NmkXSANCNo",
        "outputId": "d5fbdb8b-584c-40c9-ff7e-b1fbf22b6603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "least\n",
            "keep\n",
            "those\n",
            "hereupon\n",
            "anything\n",
            "give\n",
            "serious\n",
            "yourselves\n",
            "wherever\n",
            "someone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in about_doc:\n",
        "    if not token.is_stop:\n",
        "        print (token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOqF8BZnNHWD",
        "outputId": "88cf80d5-b96a-4318-8055-3a865db23479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Priyanka\n",
            "Raikwar\n",
            "priyanka.mnnit2020@gmail.com\n",
            "|\n",
            "+91\n",
            "-\n",
            "7974849362\n",
            "HouseNo.:33,Shivasthalicolony\n",
            ",\n",
            "Makroniya\n",
            ",\n",
            "Sagar\n",
            "|\n",
            "M.P\n",
            ",\n",
            "India\n",
            "EDUCATION\n",
            "MNNIT\n",
            "ALLAHABAD\n",
            "MASTERS\n",
            "COMPUTER\n",
            "APPLICATION\n",
            "Expected\n",
            "June\n",
            "2022\n",
            "CPI\n",
            ":\n",
            "8.6\n",
            "(\n",
            "Till\n",
            "3rdSem\n",
            ")\n",
            "DR.HARISINGHGOUR\n",
            "UNIVERSITY\n",
            ",\n",
            "SAGAR\n",
            "BACHELOR\n",
            "COMPUTER\n",
            "APPLICATION\n",
            "June\n",
            "2018\n",
            "CGPA\n",
            ":\n",
            "9.12\n",
            "CLASS\n",
            "XII\n",
            "|\n",
            "CBSE\n",
            "D.M.A\n",
            "MAKRONIYA\n",
            ",\n",
            "SAGAR\n",
            "June\n",
            "2015\n",
            "Percentage\n",
            ":\n",
            "71.33\n",
            "%\n",
            "CLASS\n",
            "X\n",
            "|\n",
            "CBSE\n",
            "D.M.A\n",
            "MAKRONIYA\n",
            ",\n",
            "SAGAR\n",
            "June\n",
            "2013\n",
            "CGPA\n",
            ":\n",
            "8.0\n",
            "LINKS\n",
            "LinkedIn://\n",
            "priyanka\n",
            "-\n",
            "raikwar-73a809152\n",
            "Hackerrank://\n",
            "Priyankajma17\n",
            "AREAOF\n",
            "INTEREST\n",
            "•Data\n",
            "Structures\n",
            "Algorithms\n",
            "•DBMS\n",
            "•Operating\n",
            "System\n",
            "•Competitive\n",
            "Coding\n",
            "SKILLS\n",
            "PROGRAMMING\n",
            "Familiar\n",
            ":\n",
            "C\n",
            "/\n",
            "C++\n",
            "•MySQL\n",
            "Basics\n",
            ":\n",
            "•\n",
            "Java\n",
            "•MongoDB\n",
            "•HTML\n",
            "•Python\n",
            "TECHNICAL\n",
            "Familiar\n",
            ":\n",
            "•\n",
            "Android\n",
            "Studio\n",
            "•\n",
            "Netbeans\n",
            "•\n",
            "Anaconda\n",
            "•\n",
            "Visual\n",
            "Studio\n",
            "•\n",
            "Postman\n",
            "CAREEROBJECTIVE\n",
            "Toworkhardwith\n",
            "dedication\n",
            "achievementof\n",
            "organizationsobjectiveunder\n",
            "sat-\n",
            "isfying\n",
            "job\n",
            "contact\n",
            ",\n",
            "enhancing\n",
            "skills\n",
            "knowledge\n",
            ".\n",
            "PROJECTS\n",
            "LIBRARYMANAGEMENT\n",
            "SYSTEM\n",
            "|\n",
            "JAVA\n",
            "/\n",
            "SWING\n",
            "July\n",
            "2020\n",
            "–\n",
            "August\n",
            "2020\n",
            "|\n",
            "Java\n",
            ",\n",
            "MySQL\n",
            "•\n",
            "Login\n",
            "students\n",
            "username\n",
            "password\n",
            ".\n",
            "•\n",
            "add\n",
            "books\n",
            "database\n",
            "issue\n",
            ".\n",
            "•\n",
            "add\n",
            "students\n",
            "details\n",
            "number\n",
            "book\n",
            "issued\n",
            "returned\n",
            ".\n",
            "•\n",
            "check\n",
            "statistics\n",
            "issued\n",
            "returned\n",
            "book\n",
            ".\n",
            "•\n",
            "Calculate\n",
            "fine\n",
            "returning\n",
            "book\n",
            "late\n",
            ".\n",
            "HANDMOVEMENTDETECTION\n",
            "|PYTHON\n",
            "March\n",
            "2021\n",
            "–\n",
            "2021\n",
            "|\n",
            "Computer\n",
            "Vision\n",
            "|\n",
            "Image\n",
            "Processing\n",
            "•\n",
            "Anaconda\n",
            "platform\n",
            ".\n",
            "•\n",
            "Libraries\n",
            "OpenCV\n",
            "andNumPy\n",
            "•\n",
            "Web\n",
            "camera\n",
            "detect\n",
            "hands\n",
            "gesture\n",
            "respond\n",
            "corresponding\n",
            ".\n",
            "•\n",
            "Operation\n",
            "included\n",
            "Pause\n",
            ",\n",
            "play\n",
            ",\n",
            "volume\n",
            ",\n",
            "volume\n",
            "fast\n",
            "forward\n",
            ".\n",
            "FINDVACCINATION\n",
            "SLOT\n",
            "|PYTHON\n",
            "|JASON\n",
            "2021\n",
            "|\n",
            "Setu\n",
            "API\n",
            "•\n",
            "Pycharm\n",
            "platform\n",
            "Postman\n",
            ".\n",
            "•\n",
            "check\n",
            "vaccinations\n",
            "slots\n",
            "PIN\n",
            "code\n",
            "date\n",
            ".\n",
            "ACHIEVEMENTS\n",
            "&\n",
            "AWARDS\n",
            "July\n",
            "2020\n",
            "Certificate\n",
            "Completion\n",
            "”\n",
            "Certified\n",
            "Network\n",
            "Security\n",
            "Specialist\n",
            "”\n",
            "(\n",
            "ICSI\n",
            ")\n",
            "2017\n",
            "Worked\n",
            "Class\n",
            "Representative\n",
            "BCA\n",
            "2017\n",
            "Got\n",
            "second\n",
            "position\n",
            "National\n",
            "Science\n",
            "Day\n",
            "Event\n",
            "EXTRACURRICULUMACTIVITY\n",
            "2019\n",
            "Member\n",
            "Volleyball\n",
            "team\n",
            "atMNNIT\n",
            "Allahabad\n",
            "2019\n",
            "Got\n",
            "gold\n",
            "medal\n",
            "kabaddi\n",
            ".\n",
            "HOBBIES\n",
            "•\n",
            "explore\n",
            "read\n",
            "new\n",
            "technologies\n",
            ".\n",
            "•\n",
            "read\n",
            "chronicles\n",
            "freedom\n",
            "fighters\n",
            "•\n",
            "Drawing\n",
            "Sketching\n",
            "1\n",
            "mailto:priyanka.mnnit2020@gmail.com\n",
            "tel\n",
            ":\n",
            "7974849362\n",
            "House\n",
            ".\n",
            ":\n",
            "33\n",
            ",\n",
            "Shivasthali\n",
            "colony\n",
            ",\n",
            "Makroniya\n",
            ",\n",
            "Sagar\n",
            "https://www.linkedin.com/in/priyanka-raikwar-73a809152\n",
            "https://www.hackerrank.com/Priyankajma17\n",
            "Education\n",
            "MNNIT\n",
            "ALLAHABAD\n",
            "Dr\n",
            ".\n",
            "Harisingh\n",
            "Gour\n",
            "University\n",
            ",\n",
            "Sagar\n",
            "Links\n",
            "Area\n",
            "Interest\n",
            "Skills\n",
            "Programming\n",
            "Technical\n",
            "CAREER\n",
            "OBJECTIVE\n",
            "PROJECTS\n",
            "Achievements\n",
            "&\n",
            "Awards\n",
            "Extra\n",
            "curriculum\n",
            "activity\n",
            "Hobbies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "about_no_stopword_doc = [token for token in about_doc if not token.is_stop]\n",
        "print (about_no_stopword_doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEI2W7SQNKNR",
        "outputId": "8a8ef9ac-a79d-4ba1-ceba-7e9af8cc697f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ , Priyanka, Raikwar, priyanka.mnnit2020@gmail.com, |, +91, -, 7974849362, HouseNo.:33,Shivasthalicolony, ,, Makroniya, ,, Sagar, |, M.P, ,, India, EDUCATION, MNNIT, ALLAHABAD, MASTERS, COMPUTER, APPLICATION, Expected, June, 2022, CPI, :, 8.6, (, Till, 3rdSem, ), DR.HARISINGHGOUR, UNIVERSITY, ,, SAGAR, BACHELOR, COMPUTER, APPLICATION, June, 2018, CGPA, :, 9.12, CLASS, XII, |, CBSE, D.M.A, MAKRONIYA, ,, SAGAR, June, 2015, Percentage, :, 71.33, %, CLASS, X, |, CBSE, D.M.A, MAKRONIYA, ,, SAGAR, June, 2013, CGPA, :, 8.0, LINKS, LinkedIn://, priyanka, -, raikwar-73a809152, Hackerrank://, Priyankajma17, AREAOF, INTEREST, •Data, Structures, Algorithms, •DBMS, •Operating, System, •Competitive, Coding, SKILLS, PROGRAMMING, Familiar, :, C, /, C++, •MySQL, Basics, :, •, Java, •MongoDB, •HTML, •Python, TECHNICAL, Familiar, :, •, Android, Studio, •, Netbeans, •, Anaconda, •, Visual, Studio, •, Postman, CAREEROBJECTIVE, Toworkhardwith, dedication, achievementof, organizationsobjectiveunder, sat-, isfying, job, contact, ,, enhancing, skills, knowledge, ., PROJECTS, LIBRARYMANAGEMENT, SYSTEM, |, JAVA, /, SWING, July, 2020, –, August, 2020, |, Java, ,, MySQL, •, Login, students, username, password, ., •, add, books, database, issue, ., •, add, students, details, number, book, issued, returned, ., •, check, statistics, issued, returned, book, ., •, Calculate, fine, returning, book, late, ., HANDMOVEMENTDETECTION, |PYTHON, March, 2021, –, 2021, |, Computer, Vision, |, Image, Processing, •, Anaconda, platform, ., •, Libraries, OpenCV, andNumPy, •, Web, camera, detect, hands, gesture, respond, corresponding, ., •, Operation, included, Pause, ,, play, ,, volume, ,, volume, fast, forward, ., FINDVACCINATION, SLOT, |PYTHON, |JASON, 2021, |, Setu, API, •, Pycharm, platform, Postman, ., •, check, vaccinations, slots, PIN, code, date, ., ACHIEVEMENTS, &, AWARDS, July, 2020, Certificate, Completion, ”, Certified, Network, Security, Specialist, ”, (, ICSI, ), 2017, Worked, Class, Representative, BCA, 2017, Got, second, position, National, Science, Day, Event, EXTRACURRICULUMACTIVITY, 2019, Member, Volleyball, team, atMNNIT, Allahabad, 2019, Got, gold, medal, kabaddi, ., HOBBIES, •, explore, read, new, technologies, ., •, read, chronicles, freedom, fighters, •, Drawing, Sketching, 1, mailto:priyanka.mnnit2020@gmail.com, tel, :, 7974849362, House, ., :, 33, ,, Shivasthali, colony, ,, Makroniya, ,, Sagar, https://www.linkedin.com/in/priyanka-raikwar-73a809152, https://www.hackerrank.com/Priyankajma17, Education, MNNIT, ALLAHABAD, Dr, ., Harisingh, Gour, University, ,, Sagar, Links, Area, Interest, Skills, Programming, Technical, CAREER, OBJECTIVE, PROJECTS, Achievements, &, Awards, Extra, curriculum, activity, Hobbies]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/filteredtext.txt'\n",
        "introduction_file_text = open(file_name).read()\n",
        "   \n",
        "conference_help_doc = nlp(introduction_file_text)\n",
        "for token in conference_help_doc:\n",
        "    print (token, token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC0FeTZ6NPRs",
        "outputId": "ec358eb0-2132-478a-978c-369e3e1fd937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "Priyanka Priyanka\n",
            "Raikwar Raikwar\n",
            "priyanka.mnnit2020@gmail.com priyanka.mnnit2020@gmail.com\n",
            "| |\n",
            "+91 +91\n",
            "- -\n",
            "7974849362 7974849362\n",
            "HouseNo.:33,Shivasthalicolony HouseNo.:33,Shivasthalicolony\n",
            ", ,\n",
            "Makroniya Makroniya\n",
            ", ,\n",
            "Sagar Sagar\n",
            "| |\n",
            "M.P M.P\n",
            ", ,\n",
            "India India\n",
            "EDUCATION EDUCATION\n",
            "MNNIT MNNIT\n",
            "ALLAHABAD ALLAHABAD\n",
            "MASTERS master\n",
            "OF of\n",
            "COMPUTER computer\n",
            "APPLICATION application\n",
            "Expected expect\n",
            "June June\n",
            "2022 2022\n",
            "CPI CPI\n",
            ": :\n",
            "8.6 8.6\n",
            "( (\n",
            "Till till\n",
            "3rdSem 3rdsem\n",
            ") )\n",
            "DR.HARISINGHGOUR DR.HARISINGHGOUR\n",
            "UNIVERSITY UNIVERSITY\n",
            ", ,\n",
            "SAGAR SAGAR\n",
            "BACHELOR BACHELOR\n",
            "OF of\n",
            "COMPUTER computer\n",
            "APPLICATION APPLICATION\n",
            "June June\n",
            "2018 2018\n",
            "CGPA CGPA\n",
            ": :\n",
            "9.12 9.12\n",
            "CLASS CLASS\n",
            "XII XII\n",
            "| |\n",
            "CBSE CBSE\n",
            "D.M.A D.M.A\n",
            "MAKRONIYA MAKRONIYA\n",
            ", ,\n",
            "SAGAR SAGAR\n",
            "June June\n",
            "2015 2015\n",
            "Percentage Percentage\n",
            ": :\n",
            "71.33 71.33\n",
            "% %\n",
            "CLASS CLASS\n",
            "X X\n",
            "| |\n",
            "CBSE CBSE\n",
            "D.M.A D.M.A\n",
            "MAKRONIYA MAKRONIYA\n",
            ", ,\n",
            "SAGAR SAGAR\n",
            "June June\n",
            "2013 2013\n",
            "CGPA CGPA\n",
            ": :\n",
            "8.0 8.0\n",
            "LINKS link\n",
            "LinkedIn:// linkedin://\n",
            "priyanka priyanka\n",
            "- -\n",
            "raikwar-73a809152 raikwar-73a809152\n",
            "Hackerrank:// hackerrank://\n",
            "Priyankajma17 priyankajma17\n",
            "AREAOF areaof\n",
            "INTEREST interest\n",
            "•Data •Data\n",
            "Structures structure\n",
            "Algorithms Algorithms\n",
            "•DBMS •DBMS\n",
            "•Operating •operate\n",
            "System System\n",
            "•Competitive •Competitive\n",
            "Coding code\n",
            "SKILLS skills\n",
            "PROGRAMMING programming\n",
            "Familiar Familiar\n",
            "with with\n",
            ": :\n",
            "C C\n",
            "/ /\n",
            "C++ C++\n",
            "•MySQL •mysql\n",
            "Basics basic\n",
            ": :\n",
            "• •\n",
            "Java Java\n",
            "•MongoDB •MongoDB\n",
            "•HTML •HTML\n",
            "•Python •python\n",
            "TECHNICAL technical\n",
            "Familiar familiar\n",
            "with with\n",
            ": :\n",
            "• •\n",
            "Android Android\n",
            "Studio Studio\n",
            "• •\n",
            "Netbeans Netbeans\n",
            "• •\n",
            "Anaconda anaconda\n",
            "• •\n",
            "Visual visual\n",
            "Studio Studio\n",
            "• •\n",
            "Postman Postman\n",
            "CAREEROBJECTIVE CAREEROBJECTIVE\n",
            "Toworkhardwith toworkhardwith\n",
            "full full\n",
            "dedication dedication\n",
            "achievementof achievementof\n",
            "organizationsobjectiveunder organizationsobjectiveunder\n",
            "sat- sat-\n",
            "isfying isfye\n",
            "job job\n",
            "contact contact\n",
            ", ,\n",
            "hence hence\n",
            "enhancing enhance\n",
            "skills skill\n",
            "knowledge knowledge\n",
            ". .\n",
            "PROJECTS PROJECTS\n",
            "LIBRARYMANAGEMENT LIBRARYMANAGEMENT\n",
            "SYSTEM SYSTEM\n",
            "| |\n",
            "JAVA JAVA\n",
            "/ /\n",
            "SWING SWING\n",
            "July July\n",
            "2020 2020\n",
            "– –\n",
            "August August\n",
            "2020 2020\n",
            "| |\n",
            "Java Java\n",
            ", ,\n",
            "MySQL MySQL\n",
            "• •\n",
            "Login login\n",
            "students student\n",
            "username username\n",
            "password password\n",
            ". .\n",
            "• •\n",
            "Can Can\n",
            "add add\n",
            "books book\n",
            "database database\n",
            "issue issue\n",
            "them -PRON-\n",
            ". .\n",
            "• •\n",
            "Can Can\n",
            "add add\n",
            "students student\n",
            "see see\n",
            "details detail\n",
            "number number\n",
            "book book\n",
            "issued issue\n",
            "returned return\n",
            ". .\n",
            "• •\n",
            "Can Can\n",
            "check check\n",
            "statistics statistic\n",
            "issued issue\n",
            "returned return\n",
            "book book\n",
            ". .\n",
            "• •\n",
            "Calculate calculate\n",
            "fine fine\n",
            "returning return\n",
            "book book\n",
            "late late\n",
            ". .\n",
            "HANDMOVEMENTDETECTION handmovementdetection\n",
            "|PYTHON |PYTHON\n",
            "March March\n",
            "2021 2021\n",
            "– –\n",
            "May May\n",
            "2021 2021\n",
            "| |\n",
            "Computer Computer\n",
            "Vision Vision\n",
            "| |\n",
            "Image Image\n",
            "Processing processing\n",
            "• •\n",
            "Using use\n",
            "Anaconda Anaconda\n",
            "platform platform\n",
            ". .\n",
            "• •\n",
            "Libraries library\n",
            "used use\n",
            "OpenCV OpenCV\n",
            "andNumPy andNumPy\n",
            "• •\n",
            "Web web\n",
            "camera camera\n",
            "detect detect\n",
            "hands hand\n",
            "gesture gesture\n",
            "respond respond\n",
            "corresponding correspond\n",
            "it -PRON-\n",
            ". .\n",
            "• •\n",
            "Operation operation\n",
            "included include\n",
            "Pause Pause\n",
            ", ,\n",
            "play play\n",
            ", ,\n",
            "volume volume\n",
            "up up\n",
            ", ,\n",
            "volume volume\n",
            "fast fast\n",
            "forward forward\n",
            ". .\n",
            "FINDVACCINATION FINDVACCINATION\n",
            "SLOT SLOT\n",
            "|PYTHON |PYTHON\n",
            "|JASON |JASON\n",
            "May May\n",
            "2021 2021\n",
            "| |\n",
            "Using use\n",
            "Setu Setu\n",
            "API api\n",
            "• •\n",
            "Using use\n",
            "Pycharm Pycharm\n",
            "platform platform\n",
            "Postman Postman\n",
            ". .\n",
            "• •\n",
            "Can Can\n",
            "check check\n",
            "vaccinations vaccination\n",
            "slots slot\n",
            "PIN pin\n",
            "code code\n",
            "date date\n",
            ". .\n",
            "ACHIEVEMENTS ACHIEVEMENTS\n",
            "& &\n",
            "AWARDS AWARDS\n",
            "July July\n",
            "2020 2020\n",
            "Certificate Certificate\n",
            "Completion Completion\n",
            "” \"\n",
            "Certified Certified\n",
            "Network Network\n",
            "Security Security\n",
            "Specialist Specialist\n",
            "” \"\n",
            "( (\n",
            "ICSI ICSI\n",
            ") )\n",
            "2017 2017\n",
            "Worked Worked\n",
            "Class Class\n",
            "Representative Representative\n",
            "BCA BCA\n",
            "2017 2017\n",
            "Got got\n",
            "second second\n",
            "position position\n",
            "National National\n",
            "Science Science\n",
            "Day Day\n",
            "Event Event\n",
            "EXTRACURRICULUMACTIVITY extracurriculumactivity\n",
            "2019 2019\n",
            "Member Member\n",
            "Volleyball Volleyball\n",
            "team team\n",
            "atMNNIT atmnnit\n",
            "Allahabad Allahabad\n",
            "2019 2019\n",
            "Got Got\n",
            "gold gold\n",
            "medal medal\n",
            "kabaddi kabaddi\n",
            ". .\n",
            "HOBBIES HOBBIES\n",
            "• •\n",
            "To to\n",
            "explore explore\n",
            "read read\n",
            "new new\n",
            "technologies technology\n",
            ". .\n",
            "• •\n",
            "To to\n",
            "read read\n",
            "chronicles chronicle\n",
            "freedom freedom\n",
            "fighters fighter\n",
            "• •\n",
            "Drawing draw\n",
            "Sketching Sketching\n",
            "1 1\n",
            "mailto:priyanka.mnnit2020@gmail.com mailto:priyanka.mnnit2020@gmail.com\n",
            "tel tel\n",
            ": :\n",
            "7974849362 7974849362\n",
            "House House\n",
            "No No\n",
            ". .\n",
            ": :\n",
            "33 33\n",
            ", ,\n",
            "Shivasthali Shivasthali\n",
            "colony colony\n",
            ", ,\n",
            "Makroniya Makroniya\n",
            ", ,\n",
            "Sagar Sagar\n",
            "https://www.linkedin.com/in/priyanka-raikwar-73a809152 https://www.linkedin.com/in/priyanka-raikwar-73a809152\n",
            "https://www.hackerrank.com/Priyankajma17 https://www.hackerrank.com/Priyankajma17\n",
            "Education Education\n",
            "MNNIT MNNIT\n",
            "ALLAHABAD ALLAHABAD\n",
            "Dr Dr\n",
            ". .\n",
            "Harisingh Harisingh\n",
            "Gour Gour\n",
            "University University\n",
            ", ,\n",
            "Sagar Sagar\n",
            "Links Links\n",
            "Area Area\n",
            "Interest Interest\n",
            "Skills Skills\n",
            "Programming program\n",
            "Technical technical\n",
            "CAREER career\n",
            "OBJECTIVE objective\n",
            "PROJECTS PROJECTS\n",
            "Achievements Achievements\n",
            "& &\n",
            "Awards Awards\n",
            "Extra Extra\n",
            "curriculum curriculum\n",
            "activity activity\n",
            "Hobbies hobby\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nouns = []\n",
        "adjectives = []\n",
        "for token in about_doc:\n",
        "    if token.pos_ == 'NOUN':\n",
        "        nouns.append(token)\n",
        "    if token.pos_ == 'ADJ':\n",
        "        adjectives.append(token)\n",
        "\n",
        "nouns\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLUElDjvPTzd",
        "outputId": "8e7a7015-ca4b-4cdd-ae3d-22d07cdd545d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[MASTERS,\n",
              " COMPUTER,\n",
              " APPLICATION,\n",
              " BACHELOR,\n",
              " COMPUTER,\n",
              " %,\n",
              " LINKS,\n",
              " priyanka,\n",
              " INTEREST,\n",
              " •Data,\n",
              " Structures,\n",
              " SKILLS,\n",
              " PROGRAMMING,\n",
              " •MySQL,\n",
              " Basics,\n",
              " •Python,\n",
              " TECHNICAL,\n",
              " Anaconda,\n",
              " dedication,\n",
              " organizationsobjectiveunder,\n",
              " job,\n",
              " contact,\n",
              " knowledge,\n",
              " students,\n",
              " password,\n",
              " books,\n",
              " database,\n",
              " students,\n",
              " details,\n",
              " number,\n",
              " book,\n",
              " statistics,\n",
              " book,\n",
              " book,\n",
              " HANDMOVEMENTDETECTION,\n",
              " Processing,\n",
              " platform,\n",
              " Libraries,\n",
              " Web,\n",
              " camera,\n",
              " hands,\n",
              " gesture,\n",
              " respond,\n",
              " Operation,\n",
              " play,\n",
              " volume,\n",
              " volume,\n",
              " API,\n",
              " platform,\n",
              " vaccinations,\n",
              " slots,\n",
              " PIN,\n",
              " code,\n",
              " date,\n",
              " position,\n",
              " EXTRACURRICULUMACTIVITY,\n",
              " team,\n",
              " gold,\n",
              " medal,\n",
              " kabaddi,\n",
              " technologies,\n",
              " chronicles,\n",
              " freedom,\n",
              " fighters,\n",
              " tel,\n",
              " colony,\n",
              " CAREER,\n",
              " OBJECTIVE,\n",
              " curriculum,\n",
              " activity,\n",
              " Hobbies]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Mjrjm3kgP_so"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}